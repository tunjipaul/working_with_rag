{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Embeddings Deep Dive\n",
    "\n",
    "**Level:** Intermediate  \n",
    "**Prerequisites:** Modules 1 & 2 completed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "- Understand what embeddings are and how they work\n",
    "- Generate embeddings using different models\n",
    "- Calculate similarity between embeddings\n",
    "- Choose the right embedding model for your use case\n",
    "- Implement semantic search with embeddings\n",
    "- Understand embedding dimensions and trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. What Are Embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 The Core Concept\n",
    "\n",
    "**Simple Definition:**\n",
    "> Embeddings are numerical representations of text that capture meaning.\n",
    "\n",
    "**Think of it like this:**\n",
    "- Words are converted to numbers (vectors)\n",
    "- Similar meanings â†’ Similar numbers\n",
    "- Computers can then do math with meaning!\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "\"cat\"     â†’ [0.2, -0.5, 0.8, 0.1, ...] (384 numbers)\n",
    "\"kitten\"  â†’ [0.3, -0.4, 0.7, 0.2, ...] (similar numbers!)\n",
    "\"car\"     â†’ [-0.1, 0.6, -0.3, 0.9, ...] (very different numbers)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Why Do We Need Embeddings?\n",
    "\n",
    "**Problem:** Computers don't understand text\n",
    "\n",
    "**Traditional Approach (doesn't work for RAG):**\n",
    "- Keyword matching: \"cat\" only matches \"cat\"\n",
    "- Misses \"kitten\", \"feline\", \"kitty\"\n",
    "- Can't understand meaning or context\n",
    "\n",
    "**Embeddings Approach (what RAG uses):**\n",
    "- Captures semantic meaning\n",
    "- \"cat\" is similar to \"kitten\", \"feline\", \"pet\"\n",
    "- Finds relevant content even with different words\n",
    "\n",
    "**This is why embeddings enable semantic search!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Generating Your First Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Setup\n",
    "\n",
    "We'll use **sentence-transformers** - a popular, free, open-source library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required library\n",
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load an Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "âœ… Model loaded!\n",
      "Model produces 384 dimensional embeddings\n"
     ]
    }
   ],
   "source": [
    "# Load a small, fast embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"âœ… Model loaded!\")\n",
    "print(f\"Model produces {model.get_sentence_embedding_dimension()} dimensional embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: The cat sat on the mat\n",
      "Embedding shape: (384,)\n",
      "Embedding type: <class 'numpy.ndarray'>\n",
      "\n",
      "First 10 values: [ 0.13040186 -0.01187012 -0.02811704  0.05123863 -0.05597441  0.03019154\n",
      "  0.03016129  0.02469839 -0.01837056  0.05876678]\n"
     ]
    }
   ],
   "source": [
    "# Simple example\n",
    "text = \"The cat sat on the mat\"\n",
    "\n",
    "# Generate embedding\n",
    "embedding = model.encode(text)\n",
    "\n",
    "print(f\"Original text: {text}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"Embedding type: {type(embedding)}\")\n",
    "print(f\"\\nFirst 10 values: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ What just happened?\n",
    "\n",
    "- Input: 6 words\n",
    "- Output: 384 numbers (a vector)\n",
    "- These numbers capture the meaning of the sentence\n",
    "- We can now do math with this meaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Similarity: The Heart of RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Cosine Similarity Explained\n",
    "\n",
    "**Cosine similarity** measures how similar two vectors are.\n",
    "\n",
    "**Range:** -1 to 1\n",
    "- **1.0** = Identical meaning\n",
    "- **0.8-0.9** = Very similar\n",
    "- **0.5-0.7** = Somewhat related\n",
    "- **< 0.3** = Not related\n",
    "\n",
    "**Formula:** Don't worry about the math - just use the function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Similarity function ready!\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \n",
    "    Returns a score between -1 and 1 (higher = more similar)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "print(\"âœ… Similarity function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Testing Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing to: 'The cat sat on the mat'\n",
      "\n",
      "Similarity to 'The cat sat on the mat'\n",
      "Score: 1.000\n",
      "\n",
      "Similarity to 'A feline rested on the rug'\n",
      "Score: 0.564\n",
      "\n",
      "Similarity to 'Dogs are loyal animals'\n",
      "Score: 0.165\n",
      "\n",
      "Similarity to 'Python is a programming language'\n",
      "Score: 0.031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create test sentences\n",
    "sentences = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"A feline rested on the rug\",      # Similar meaning, different words\n",
    "    \"Dogs are loyal animals\",          # Different topic\n",
    "    \"Python is a programming language\" # Completely unrelated\n",
    "]\n",
    "\n",
    "# Generate embeddings for all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Compare first sentence to all others\n",
    "print(\"Comparing to: 'The cat sat on the mat'\\n\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    similarity = cosine_similarity(embeddings[0], embeddings[i])\n",
    "    print(f\"Similarity to '{sentence}'\")\n",
    "    print(f\"Score: {similarity:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Observations\n",
    "\n",
    "Notice how:\n",
    "- âœ… \"A feline rested on the rug\" has HIGH similarity (same meaning, different words)\n",
    "- âœ… \"Dogs are loyal animals\" has MEDIUM similarity (animals, but different context)\n",
    "- âœ… \"Python is a programming language\" has LOW similarity (completely different)\n",
    "\n",
    "**This is semantic search in action!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Building a Simple Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Create a Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base: 8 documents\n"
     ]
    }
   ],
   "source": [
    "# Sample knowledge base\n",
    "documents = [\n",
    "    \"Python is a high-level programming language known for simplicity\",\n",
    "    \"Machine learning enables computers to learn from data\",\n",
    "    \"Neural networks are inspired by biological brains\",\n",
    "    \"Dogs are loyal and friendly pets that need exercise\",\n",
    "    \"Cats are independent animals that make great companions\",\n",
    "    \"JavaScript is used for web development and runs in browsers\",\n",
    "    \"Deep learning uses multi-layered neural networks\",\n",
    "    \"Puppies require training and socialization from an early age\"\n",
    "]\n",
    "\n",
    "print(f\"Knowledge base: {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Embed All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for all documents...\n",
      "âœ… Created 8 embeddings\n",
      "Each embedding has 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all documents\n",
    "print(\"Generating embeddings for all documents...\")\n",
    "doc_embeddings = model.encode(documents)\n",
    "\n",
    "print(f\"âœ… Created {len(doc_embeddings)} embeddings\")\n",
    "print(f\"Each embedding has {doc_embeddings[0].shape[0]} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, documents, doc_embeddings, top_k=3):\n",
    "    \"\"\"\n",
    "    Search for documents similar to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query (string)\n",
    "        documents: List of document texts\n",
    "        doc_embeddings: Pre-computed document embeddings\n",
    "        top_k: Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of (document, similarity_score) tuples\n",
    "    \"\"\"\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for i, doc_emb in enumerate(doc_embeddings):\n",
    "        similarity = cosine_similarity(query_embedding, doc_emb)\n",
    "        similarities.append((documents[i], similarity))\n",
    "    \n",
    "    # Sort by similarity (highest first)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top k results\n",
    "    return similarities[:top_k]\n",
    "\n",
    "print(\"âœ… Search function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Try It Out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY: What is artificial intelligence?\n",
      "================================================================================\n",
      "\n",
      "1. (Score: 0.408)\n",
      "   Machine learning enables computers to learn from data\n",
      "\n",
      "2. (Score: 0.395)\n",
      "   Neural networks are inspired by biological brains\n",
      "\n",
      "3. (Score: 0.326)\n",
      "   Python is a high-level programming language known for simplicity\n",
      "\n",
      "================================================================================\n",
      "QUERY: Tell me about pet dogs\n",
      "================================================================================\n",
      "\n",
      "1. (Score: 0.548)\n",
      "   Dogs are loyal and friendly pets that need exercise\n",
      "\n",
      "2. (Score: 0.437)\n",
      "   Puppies require training and socialization from an early age\n",
      "\n",
      "3. (Score: 0.413)\n",
      "   Cats are independent animals that make great companions\n",
      "\n",
      "================================================================================\n",
      "QUERY: How do I code in Python?\n",
      "================================================================================\n",
      "\n",
      "1. (Score: 0.554)\n",
      "   Python is a high-level programming language known for simplicity\n",
      "\n",
      "2. (Score: 0.148)\n",
      "   Puppies require training and socialization from an early age\n",
      "\n",
      "3. (Score: 0.138)\n",
      "   JavaScript is used for web development and runs in browsers\n"
     ]
    }
   ],
   "source": [
    "# Test different queries\n",
    "queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"Tell me about pet dogs\",\n",
    "    \"How do I code in Python?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    results = search(query, documents, doc_embeddings, top_k=3)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. (Score: {score:.3f})\")\n",
    "        print(f\"   {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Amazing, right?\n",
    "\n",
    "Notice how:\n",
    "- \"What is artificial intelligence?\" finds ML and neural network docs\n",
    "- \"Tell me about pet dogs\" finds dog-related docs\n",
    "- \"How do I code in Python?\" finds Python programming doc\n",
    "\n",
    "**Even though the exact words don't match!** This is the power of embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Understanding Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Popular Embedding Models\n",
    "\n",
    "### Free / Open Source Models\n",
    "\n",
    "| Model | Dimensions | Speed | Best For |\n",
    "|-------|-----------|-------|----------|\n",
    "| **all-MiniLM-L6-v2** | 384 | âš¡âš¡âš¡ Fast | General purpose, **recommended starter** |\n",
    "| **all-mpnet-base-v2** | 768 | âš¡âš¡ Medium | Better quality, slower |\n",
    "| **all-MiniLM-L12-v2** | 384 | âš¡âš¡ Medium | Balance of speed and quality |\n",
    "\n",
    "### API-Based Models (require API key)\n",
    "\n",
    "| Model | Dimensions | Cost | Best For |\n",
    "|-------|-----------|------|----------|\n",
    "| **OpenAI text-embedding-3-small** | 1536 | $ | High quality, general |\n",
    "| **OpenAI text-embedding-3-large** | 3072 | $$ | Best quality, expensive |\n",
    "| **Cohere embed-english-v3.0** | 1024 | $ | Good quality, affordable |\n",
    "\n",
    "### Domain-Specific Models\n",
    "\n",
    "| Domain | Model | Why |\n",
    "|--------|-------|-----|\n",
    "| **Code** | code-search-net | Understands code syntax |\n",
    "| **Science** | allenai-specter | Trained on scientific papers |\n",
    "| **Multilingual** | paraphrase-multilingual-mpnet-base-v2 | Supports 50+ languages |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Comparing Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "\n",
      "âœ… Both models loaded!\n",
      "Small model: 384 dimensions\n",
      "Large model: 768 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Load two different models for comparison\n",
    "print(\"Loading models...\\n\")\n",
    "\n",
    "model_small = SentenceTransformer('all-MiniLM-L6-v2')      # 384 dimensions\n",
    "model_large = SentenceTransformer('all-mpnet-base-v2')     # 768 dimensions\n",
    "\n",
    "print(\"âœ… Both models loaded!\")\n",
    "print(f\"Small model: {model_small.get_sentence_embedding_dimension()} dimensions\")\n",
    "print(f\"Large model: {model_large.get_sentence_embedding_dimension()} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing model performance:\n",
      "\n",
      "Pair: 'The dog is running' vs 'A canine is jogging'\n",
      "  Small model: 0.818\n",
      "  Large model: 0.827\n",
      "\n",
      "Pair: 'I love pizza' vs 'Pizza is delicious'\n",
      "  Small model: 0.801\n",
      "  Large model: 0.785\n",
      "\n",
      "Pair: 'Python programming' vs 'Cooking pasta'\n",
      "  Small model: 0.142\n",
      "  Large model: 0.120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare on a similarity task\n",
    "test_pairs = [\n",
    "    (\"The dog is running\", \"A canine is jogging\"),           # Similar\n",
    "    (\"I love pizza\", \"Pizza is delicious\"),                  # Related\n",
    "    (\"Python programming\", \"Cooking pasta\")                  # Unrelated\n",
    "]\n",
    "\n",
    "print(\"Comparing model performance:\\n\")\n",
    "for text1, text2 in test_pairs:\n",
    "    # Small model\n",
    "    emb1_small = model_small.encode([text1, text2])\n",
    "    sim_small = cosine_similarity(emb1_small[0], emb1_small[1])\n",
    "    \n",
    "    # Large model  \n",
    "    emb1_large = model_large.encode([text1, text2])\n",
    "    sim_large = cosine_similarity(emb1_large[0], emb1_large[1])\n",
    "    \n",
    "    print(f\"Pair: '{text1}' vs '{text2}'\")\n",
    "    print(f\"  Small model: {sim_small:.3f}\")\n",
    "    print(f\"  Large model: {sim_large:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Model Selection Guide\n",
    "\n",
    "**Choose based on:**\n",
    "\n",
    "1. **Speed vs Quality**\n",
    "   - Need fast? â†’ all-MiniLM-L6-v2\n",
    "   - Need best quality? â†’ all-mpnet-base-v2 or API models\n",
    "\n",
    "2. **Cost**\n",
    "   - Free / Local â†’ sentence-transformers models\n",
    "   - Budget for API â†’ OpenAI, Cohere\n",
    "\n",
    "3. **Domain**\n",
    "   - General text â†’ all-MiniLM-L6-v2 (start here!)\n",
    "   - Code â†’ code-specific model\n",
    "   - Science â†’ scientific model\n",
    "   - Multiple languages â†’ multilingual model\n",
    "\n",
    "**For most cases: Start with all-MiniLM-L6-v2, then upgrade if needed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Embedding Dimensions Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 What Are Dimensions?\n",
    "\n",
    "**Dimensions = How many numbers represent each piece of text**\n",
    "\n",
    "**Common sizes:**\n",
    "- 384 dimensions (small, fast)\n",
    "- 768 dimensions (medium)\n",
    "- 1536 dimensions (large, high quality)\n",
    "\n",
    "## 6.2 The Trade-off\n",
    "\n",
    "### More Dimensions\n",
    "**Pros:**\n",
    "- Can capture more nuanced meaning\n",
    "- Better quality (usually)\n",
    "- Better performance on complex tasks\n",
    "\n",
    "**Cons:**\n",
    "- Slower to compute\n",
    "- More storage space\n",
    "- More expensive (if using APIs)\n",
    "\n",
    "### Fewer Dimensions\n",
    "**Pros:**\n",
    "- Faster computation\n",
    "- Less storage\n",
    "- Lower cost\n",
    "\n",
    "**Cons:**\n",
    "- May miss subtle differences\n",
    "- Lower quality (sometimes)\n",
    "\n",
    "**Reality:** For most RAG use cases, 384-768 dimensions work great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Practical Tips for Using Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Best Practices\n",
    "\n",
    "### âœ… DO:\n",
    "\n",
    "1. **Use the same model for queries and documents**\n",
    "   - MUST use identical model for both\n",
    "   - Different models = incompatible vectors\n",
    "\n",
    "2. **Embed at the right granularity**\n",
    "   - Usually: Embed chunks, not whole documents\n",
    "   - From Module 2: 300-600 token chunks work well\n",
    "\n",
    "### âŒ DON'T:\n",
    "\n",
    "1. **Mix different embedding models**\n",
    "   - Can't compare vectors from different models\n",
    "   - Must re-embed everything if changing models\n",
    "\n",
    "2. **Embed extremely long texts**\n",
    "   - Models have max length (usually 256-512 tokens)\n",
    "   - Longer text gets truncated\n",
    "   - Chunk first, then embed\n",
    "\n",
    "3. **Re-embed everything on every query**\n",
    "   - Wasteful and slow\n",
    "   - Embed documents once, store embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Common Issues and Solutions\n",
    "\n",
    "### Issue 1: Similarity Scores Too Low\n",
    "**Problem:** All similarities < 0.3\n",
    "**Solution:** \n",
    "- Check if using same model for query and docs\n",
    "- Try a better quality model\n",
    "- Check if chunks are too large/small\n",
    "\n",
    "### Issue 2: Everything Seems Similar\n",
    "**Problem:** All similarities > 0.8  \n",
    "**Solution:**\n",
    "- Chunks might be too similar (duplicate content)\n",
    "- Model might not be domain-appropriate\n",
    "- Need more diverse document set\n",
    "\n",
    "### Issue 3: Slow Embedding Generation\n",
    "**Problem:** Takes too long to embed   \n",
    "**Solution:**\n",
    "- Use smaller model (384 dims vs 768)\n",
    "- Batch process documents\n",
    "- Use GPU if available\n",
    "- Consider API-based models for scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. Complete Example: Building a Mini RAG Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine chunking (Module 2) with embeddings (Module 3) to build a simple retriever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRetriever:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize retriever with embedding model.\n",
    "        \"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.chunks = []\n",
    "        self.embeddings = None\n",
    "    \n",
    "    def add_documents(self, documents, chunk_size=500):\n",
    "        \"\"\"\n",
    "        Add documents to the retriever (chunks and embeds them).\n",
    "        \"\"\"\n",
    "        # Simple chunking (from Module 2)\n",
    "        for doc in documents:\n",
    "            words = doc.split()\n",
    "            for i in range(0, len(words), chunk_size):\n",
    "                chunk = ' '.join(words[i:i+chunk_size])\n",
    "                self.chunks.append(chunk)\n",
    "        \n",
    "        # Generate embeddings\n",
    "        print(f\"Embedding {len(self.chunks)} chunks...\")\n",
    "        self.embeddings = self.model.encode(self.chunks)\n",
    "        print(f\"âœ… Ready! {len(self.chunks)} chunks indexed.\")\n",
    "    \n",
    "    def search(self, query, top_k=3):\n",
    "        \"\"\"\n",
    "        Search for relevant chunks.\n",
    "        \"\"\"\n",
    "        # Embed query\n",
    "        query_embedding = self.model.encode(query)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = []\n",
    "        for i, chunk_emb in enumerate(self.embeddings):\n",
    "            sim = cosine_similarity(query_embedding, chunk_emb)\n",
    "            similarities.append((self.chunks[i], sim))\n",
    "        \n",
    "        # Sort and return top k\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:top_k]\n",
    "\n",
    "print(\"âœ… SimpleRetriever class ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it with sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Python is a versatile programming language widely used in web development,\n",
    "    data science, and automation. Its simple syntax makes it beginner-friendly\n",
    "    while remaining powerful for advanced applications.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Machine learning is a subset of artificial intelligence that enables systems\n",
    "    to learn and improve from experience. Popular frameworks include TensorFlow,\n",
    "    PyTorch, and scikit-learn.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Dogs are loyal companions that require regular exercise, training, and\n",
    "    veterinary care. Different breeds have varying needs and temperaments.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Create retriever and add documents\n",
    "retriever = SimpleRetriever()\n",
    "retriever.add_documents(sample_docs, chunk_size=100)\n",
    "\n",
    "# Test searches\n",
    "test_queries = [\n",
    "    \"How do I start learning to code?\",\n",
    "    \"What is AI and machine learning?\",\n",
    "    \"Tell me about caring for pets\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    results = retriever.search(query, top_k=2)\n",
    "    for i, (chunk, score) in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i} (Score: {score:.3f}):\")\n",
    "        print(chunk.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ‰ You just built a retriever!\n",
    "\n",
    "This combines:\n",
    "- âœ… Chunking (Module 2)\n",
    "- âœ… Embeddings (Module 3)\n",
    "- âœ… Similarity search\n",
    "\n",
    "**Next step:** Add vector storage (Module 4) for better performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 9. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Embeddings convert text to numbers** that capture semantic meaning\n",
    "\n",
    "2. **Similar meanings â†’ Similar numbers** (vectors)\n",
    "\n",
    "3. **Cosine similarity** measures how similar two embeddings are (0-1 scale)\n",
    "\n",
    "4. **Model choice matters:**\n",
    "   - Start with: all-MiniLM-L6-v2 (384 dims)\n",
    "   - Need better quality: all-mpnet-base-v2 (768 dims)\n",
    "   - Specific domain: Use domain-specific models\n",
    "\n",
    "5. **Must use same model** for documents and queries\n",
    "\n",
    "6. **Embed once, store forever** - don't re-embed on every query\n",
    "\n",
    "7. **Dimensions:** More isn't always better - 384-768 works for most cases\n",
    "\n",
    "8. **This enables semantic search** - the core of RAG retrieval!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Practice Exercises\n",
    "\n",
    "## Exercise 1: Understanding Embedding Similarity\n",
    "\n",
    "### Task\n",
    "Explore how embeddings capture semantic similarity between different texts.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Use the sample sentences below:\n",
    "\n",
    "```python\n",
    "sentences = [\n",
    "    \"The dog is playing in the park\",\n",
    "    \"A puppy is running outside\",\n",
    "    \"The cat is sleeping on the couch\",\n",
    "    \"Python is a programming language\",\n",
    "    \"Machine learning models need data\",\n",
    "    \"I love coding in Python\"\n",
    "]\n",
    "```\n",
    "\n",
    "2. Generate embeddings for all sentences using `all-MiniLM-L6-v2`\n",
    "\n",
    "3. Calculate similarity scores between:\n",
    "   - Sentence 1 and all others\n",
    "   - Sentence 4 and all others\n",
    "\n",
    "4. Answer these questions:\n",
    "   - Which sentences are most similar to \"The dog is playing in the park\"?\n",
    "   - Which sentences are most similar to \"Python is a programming language\"?\n",
    "   - What similarity threshold would you use to filter unrelated content?\n",
    "\n",
    "### Expected Output\n",
    "\n",
    "```\n",
    "Similarity Analysis:\n",
    "\n",
    "Query: \"The dog is playing in the park\"\n",
    "Most similar: ?\n",
    "Least similar: ?\n",
    "Observations: ?\n",
    "\n",
    "Query: \"Python is a programming language\"\n",
    "Most similar: ?\n",
    "Least similar: ?\n",
    "Observations: ?\n",
    "\n",
    "Recommended similarity threshold: ?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Chunk Size Impact on Retrieval\n",
    "\n",
    "### Task\n",
    "Understand how chunk size affects retrieval quality.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Use this long document:\n",
    "\n",
    "```python\n",
    "document = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
    "the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
    "the field as the study of intelligent agents: any device that perceives its environment\n",
    "and takes actions that maximize its chance of successfully achieving its goals.\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that focuses on the use of data\n",
    "and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
    "Machine learning is an important component of the growing field of data science.\n",
    "\n",
    "Deep learning is part of a broader family of machine learning methods based on artificial\n",
    "neural networks with representation learning. Learning can be supervised, semi-supervised\n",
    "or unsupervised. Deep learning architectures such as deep neural networks, deep belief\n",
    "networks, recurrent neural networks and convolutional neural networks have been applied\n",
    "to fields including computer vision, speech recognition, natural language processing,\n",
    "machine translation, and bioinformatics.\n",
    "\n",
    "Natural language processing is a subfield of linguistics, computer science, and artificial\n",
    "intelligence concerned with the interactions between computers and human language, in\n",
    "particular how to program computers to process and analyze large amounts of natural\n",
    "language data. Challenges in natural language processing frequently involve speech\n",
    "recognition, natural language understanding, and natural language generation.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "2. Chunk this document using 3 different sizes:\n",
    "   - Small: 100 characters\n",
    "   - Medium: 200 characters\n",
    "   - Large: 400 characters\n",
    "\n",
    "3. For each chunk size:\n",
    "   - Create embeddings\n",
    "   - Test with query: \"What is machine learning?\"\n",
    "   - Retrieve top 3 chunks\n",
    "\n",
    "4. Compare results:\n",
    "   - Which chunk size gave the most focused answer?\n",
    "   - Which gave the most complete answer?\n",
    "   - Which had the best balance?\n",
    "\n",
    "### Expected Output\n",
    "\n",
    "```\n",
    "Chunk Size Comparison:\n",
    "\n",
    "Small Chunks (100 chars):\n",
    "- Number of chunks: ?\n",
    "- Top result: \"?\"\n",
    "- Score: ?\n",
    "- Analysis: ?\n",
    "\n",
    "Medium Chunks (200 chars):\n",
    "- Number of chunks: ?\n",
    "- Top result: \"?\"\n",
    "- Score: ?\n",
    "- Analysis: ?\n",
    "\n",
    "Large Chunks (400 chars):\n",
    "- Number of chunks: ?\n",
    "- Top result: \"?\"\n",
    "- Score: ?\n",
    "- Analysis: ?\n",
    "\n",
    "Best chunk size for this use case: ? because ?\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "In **Module 4: Vector Storage & Retrieval**, you'll learn:\n",
    "- How to store millions of embeddings efficiently\n",
    "- Vector databases (FAISS, Chroma, Pinecone)\n",
    "- Fast similarity search at scale\n",
    "- Building a production-ready retriever\n",
    "\n",
    "Get ready to handle real-world scale! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "publica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
