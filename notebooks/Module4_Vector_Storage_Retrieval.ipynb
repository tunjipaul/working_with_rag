{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Vector Storage & Retrieval\n",
    "\n",
    " **Level:** Intermediate  \n",
    "**Prerequisites:** Modules 1, 2, and 3 completed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "- Understand what vector databases are and why they're needed\n",
    "- Choose the right vector database for your use case\n",
    "- Implement vector storage using FAISS (local)\n",
    "- Implement vector storage using Chroma (embedded)\n",
    "- Perform efficient similarity search at scale\n",
    "- Add filtering and metadata to retrieval\n",
    "- Optimize retrieval performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Why Vector Databases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 The Problem with Simple Storage\n",
    "\n",
    "In Module 3, we stored embeddings in a Python list and did linear search:\n",
    "\n",
    "```python\n",
    "# Simple approach from Module 3\n",
    "embeddings = [emb1, emb2, emb3, ...]  # List of vectors\n",
    "\n",
    "# Search: compare query to EVERY vector\n",
    "for emb in embeddings:\n",
    "    similarity = cosine_similarity(query_emb, emb)\n",
    "```\n",
    "\n",
    "**This works for small datasets but fails at scale:**\n",
    "\n",
    "| Documents | Vectors | Search Time |\n",
    "|-----------|---------|-------------|\n",
    "| 100 | 100 | ~10ms |\n",
    "| 1,000 | 1,000 | ~100ms |\n",
    "| 10,000 | 10,000 | ~1 second |\n",
    "| 100,000 | 100,000 | ~10 seconds |\n",
    "| 1,000,000 | 1,000,000 | ~100 seconds |\n",
    "\n",
    "**Real-world RAG systems have millions of vectors. We need a better solution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 What is a Vector Database?\n",
    "\n",
    "A vector database is a specialized database designed to:\n",
    "- Store high-dimensional vectors efficiently\n",
    "- Perform fast similarity search (even with millions of vectors)\n",
    "- Handle metadata alongside vectors\n",
    "- Support filtering and hybrid search\n",
    "\n",
    "**Key difference from regular databases:**\n",
    "- Regular DB: Exact match queries (`WHERE name = 'John'`)\n",
    "- Vector DB: Similarity queries (`Find vectors most similar to query vector`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Popular Vector Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Comparison Table\n",
    "\n",
    "| Database | Type | Best For | Pros | Cons |\n",
    "|----------|------|----------|------|------|\n",
    "| **FAISS** | Library (local) | Prototyping, research | Fast, free, flexible | No server, no persistence by default |\n",
    "| **Chroma** | Embedded | Small to medium projects | Easy setup, built for LLMs | Limited scale |\n",
    "| **Pinecone** | Cloud (managed) | Production, scale | Fully managed, scalable | Costs money, cloud-only |\n",
    "| **Weaviate** | Self-hosted/Cloud | Production, flexibility | Feature-rich, open source | Complex setup |\n",
    "| **Qdrant** | Self-hosted/Cloud | Production, performance | Fast, great filtering | Requires setup |\n",
    "| **Milvus** | Self-hosted/Cloud | Large scale, enterprise | Very scalable, mature | Complex, resource-intensive |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Decision Guide\n",
    "\n",
    "**Use FAISS when:**\n",
    "- Learning and prototyping\n",
    "- Running locally without server\n",
    "- Need maximum speed and flexibility\n",
    "- Don't need persistence (or can handle it yourself)\n",
    "\n",
    "**Use Chroma when:**\n",
    "- Building small to medium RAG apps\n",
    "- Want simplicity and easy setup\n",
    "- Need basic persistence and metadata\n",
    "- Working with LangChain or LlamaIndex\n",
    "\n",
    "**Use Pinecone when:**\n",
    "- Building production applications\n",
    "- Want fully managed service (no DevOps)\n",
    "- Need to scale to millions of vectors\n",
    "- Have budget for managed service\n",
    "\n",
    "**Use Weaviate/Qdrant when:**\n",
    "- Need production features but want to self-host\n",
    "- Want advanced filtering and hybrid search\n",
    "- Have DevOps resources\n",
    "\n",
    "**For this module, we'll focus on FAISS and Chroma (most common for learning).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Hands-On: FAISS Vector Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install -q faiss-cpu sentence-transformers numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS version: 1.13.1\n",
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(f\"FAISS version: {faiss.__version__}\")\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prepare Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 10\n"
     ]
    }
   ],
   "source": [
    "# Sample documents\n",
    "documents = [\n",
    "    \"Python is a versatile programming language used for web development and data science.\",\n",
    "    \"Machine learning models require large amounts of training data to perform well.\",\n",
    "    \"Neural networks are inspired by the structure of the human brain.\",\n",
    "    \"Natural language processing enables computers to understand human language.\",\n",
    "    \"Deep learning is a subset of machine learning using multi-layered neural networks.\",\n",
    "    \"Data visualization helps communicate insights from complex datasets.\",\n",
    "    \"Cloud computing provides on-demand access to computing resources.\",\n",
    "    \"Cybersecurity protects systems and networks from digital attacks.\",\n",
    "    \"Blockchain technology enables secure, decentralized transactions.\",\n",
    "    \"Quantum computing uses quantum mechanics to solve complex problems.\"\n",
    "]\n",
    "\n",
    "print(f\"Total documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 embeddings\n",
      "Each embedding has 384 dimensions\n",
      "Embeddings shape: (10, 384)\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(documents)\n",
    "\n",
    "print(f\"Generated {len(embeddings)} embeddings\")\n",
    "print(f\"Each embedding has {embeddings.shape[1]} dimensions\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Create FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS index created!\n",
      "Total vectors in index: 10\n"
     ]
    }
   ],
   "source": [
    "# Get embedding dimension\n",
    "dimension = embeddings.shape[1]\n",
    "\n",
    "# Create FAISS index (IndexFlatL2 = exact search with L2 distance)\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to index\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"âœ… FAISS index created!\")\n",
    "print(f\"Total vectors in index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Understanding FAISS Indexes\n",
    "\n",
    "**IndexFlatL2**: Exact search using L2 (Euclidean) distance. Best for small datasets or when you need perfect accuracy.\n",
    "\n",
    "**Other index types:**\n",
    "- `IndexFlatIP`: Exact search using inner product (similar to cosine similarity)\n",
    "- `IndexIVFFlat`: Approximate search using clustering (faster for large datasets)\n",
    "- `IndexHNSWFlat`: Graph-based approximate search (very fast)\n",
    "\n",
    "### What is the purpose of an index?\n",
    "ðŸ‘‰ 1. Store vectors efficiently\n",
    "\n",
    "The index is a special data structure that stores your embeddings (vector representations of text).\n",
    "\n",
    "ðŸ‘‰ 2. Allow fast similarity search\n",
    "\n",
    "Instead of scanning all vectors one by one (slow), the index uses algorithms to find the closest vectors very fast, even when you have millions.\n",
    "\n",
    "ðŸ‘‰ 3. Provide distance + nearest neighbors\n",
    "\n",
    "When you search with a query vector, the index returns:\n",
    "\n",
    "- I â†’ indices of the closest stored vectors\n",
    "- D â†’ distances showing how similar they are\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "I = [[5, 12, 3]]   # best matches\n",
    "D = [[0.12, 0.34, 0.89]]   # distances\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Search with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is artificial intelligence and machine learning?\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "1. (Distance: 0.9079)\n",
      "   Deep learning is a subset of machine learning using multi-layered neural networks.\n",
      "\n",
      "2. (Distance: 1.2202)\n",
      "   Machine learning models require large amounts of training data to perform well.\n",
      "\n",
      "3. (Distance: 1.2355)\n",
      "   Natural language processing enables computers to understand human language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query\n",
    "query = \"What is artificial intelligence and machine learning?\"\n",
    "\n",
    "# Embed query\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "# Search: find top 3 most similar vectors\n",
    "k = 3\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Top {k} results:\\n\")\n",
    "\n",
    "for i, (idx, distance) in enumerate(zip(indices[0], distances[0]), 1):\n",
    "    print(f\"{i}. (Distance: {distance:.4f})\")\n",
    "    print(f\"   {documents[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Understanding Distances\n",
    "\n",
    "**L2 distance** (what IndexFlatL2 uses):\n",
    "- **Lower = More similar** (opposite of cosine similarity!)\n",
    "- 0 = Identical vectors\n",
    "- Higher values = More different\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Using Cosine Similarity with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is artificial intelligence and machine learning?\n",
      "\n",
      "Top 3 results with cosine similarity:\n",
      "\n",
      "1. (Similarity: 0.5460)\n",
      "   Deep learning is a subset of machine learning using multi-layered neural networks.\n",
      "\n",
      "2. (Similarity: 0.3899)\n",
      "   Machine learning models require large amounts of training data to perform well.\n",
      "\n",
      "3. (Similarity: 0.3823)\n",
      "   Natural language processing enables computers to understand human language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalize embeddings for cosine similarity\n",
    "embeddings_normalized = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Create index with inner product (equivalent to cosine for normalized vectors)\n",
    "index_cosine = faiss.IndexFlatIP(dimension)\n",
    "index_cosine.add(embeddings_normalized)\n",
    "\n",
    "# Search with normalized query\n",
    "query_embedding_normalized = query_embedding / np.linalg.norm(query_embedding)\n",
    "scores, indices = index_cosine.search(query_embedding_normalized, k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Top {k} results with cosine similarity:\\n\")\n",
    "\n",
    "for i, (idx, score) in enumerate(zip(indices[0], scores[0]), 1):\n",
    "    print(f\"{i}. (Similarity: {score:.4f})\")\n",
    "    print(f\"   {documents[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Saving and Loading FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Index saved to disk\n",
      "âœ… Documents saved\n"
     ]
    }
   ],
   "source": [
    "# Save index to disk\n",
    "faiss.write_index(index_cosine, \"my_faiss_index.bin\")\n",
    "print(\"âœ… Index saved to disk\")\n",
    "\n",
    "# Save documents separately (FAISS only stores vectors, not text)\n",
    "import pickle\n",
    "with open(\"documents.pkl\", \"wb\") as f:\n",
    "    pickle.dump(documents, f)\n",
    "print(\"âœ… Documents saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Index loaded: 10 vectors\n",
      "âœ… Documents loaded: 10 documents\n"
     ]
    }
   ],
   "source": [
    "# Load index from disk\n",
    "loaded_index = faiss.read_index(\"my_faiss_index.bin\")\n",
    "print(f\"âœ… Index loaded: {loaded_index.ntotal} vectors\")\n",
    "\n",
    "# Load documents\n",
    "with open(\"documents.pkl\", \"rb\") as f:\n",
    "    loaded_documents = pickle.load(f)\n",
    "print(f\"âœ… Documents loaded: {len(loaded_documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Hands-On: Chroma Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Why Chroma?\n",
    "\n",
    "**Chroma advantages over FAISS:**\n",
    "- Built specifically for LLM applications\n",
    "- Automatic persistence (saves to disk automatically)\n",
    "- Stores documents AND embeddings together\n",
    "- Rich metadata support and filtering\n",
    "\n",
    "**Trade-off:** Less flexible than FAISS, not as fast for very large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [21 lines of output]\n",
      "      + C:\\Users\\hp pc\\Desktop\\TunjiPaul\\working_with_rag\\myenv\\Scripts\\python.exe C:\\Users\\hp pc\\AppData\\Local\\Temp\\pip-install-ae4jwuw7\\numpy_f9223bc76b6144e29286f33a79206d81\\vendored-meson\\meson\\meson.py setup C:\\Users\\hp pc\\AppData\\Local\\Temp\\pip-install-ae4jwuw7\\numpy_f9223bc76b6144e29286f33a79206d81 C:\\Users\\hp pc\\AppData\\Local\\Temp\\pip-install-ae4jwuw7\\numpy_f9223bc76b6144e29286f33a79206d81\\.mesonpy-qz6wf07n -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\hp pc\\AppData\\Local\\Temp\\pip-install-ae4jwuw7\\numpy_f9223bc76b6144e29286f33a79206d81\\.mesonpy-qz6wf07n\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.2.99\n",
      "      Source dir: C:\\Users\\hp pc\\AppData\\Local\\Temp\\pip-install-ae4jwuw7\\numpy_f9223bc76b6144e29286f33a79206d81\n",
      "      Build dir: C:\\Users\\hp pc\\AppData\\Local\\Temp\\pip-install-ae4jwuw7\\numpy_f9223bc76b6144e29286f33a79206d81\\.mesonpy-qz6wf07n\n",
      "      Build type: native build\n",
      "      Project name: NumPy\n",
      "      Project version: 1.26.4\n",
      "      WARNING: Failed to activate VS environment: Could not parse vswhere.exe output\n",
      "      \n",
      "      ..\\meson.build:1:0: ERROR: Unknown compiler(s): [['icl'], ['cl'], ['cc'], ['gcc'], ['clang'], ['clang-cl'], ['pgcc']]\n",
      "      The following exception(s) were encountered:\n",
      "      Running `icl \"\"` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `cc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `gcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `clang --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `clang-cl /?` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      Running `pgcc --version` gave \"[WinError 2] The system cannot find the file specified\"\n",
      "      \n",
      "      A full log can be found at C:\\Users\\hp pc\\AppData\\Local\\Temp\\pip-install-ae4jwuw7\\numpy_f9223bc76b6144e29286f33a79206d81\\.mesonpy-qz6wf07n\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Ã— Encountered error while generating package metadata.\n",
      "â•°â”€> numpy\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (25.2)\n",
      "Collecting pip\n",
      "  Using cached pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached pip-25.3-py3-none-any.whl (1.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\hp pc\\Desktop\\TunjiPaul\\working_with_rag\\myenv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticImportError",
     "evalue": "`BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.12/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.12/u/import-error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPydanticImportError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChromaDB version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromadb.__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… ChromaDB imported successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp pc\\Desktop\\TunjiPaul\\working_with_rag\\myenv\\Lib\\site-packages\\chromadb\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtelemetry\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ClientStartEvent\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp pc\\Desktop\\TunjiPaul\\working_with_rag\\myenv\\Lib\\site-packages\\chromadb\\config.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSettings\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[32m      4\u001b[39m TELEMETRY_WHITELISTED_SETTINGS = [\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mchroma_db_impl\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mchroma_api_impl\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mchroma_server_ssl_enabled\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp pc\\Desktop\\TunjiPaul\\working_with_rag\\myenv\\Lib\\site-packages\\pydantic\\__init__.py:437\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m    435\u001b[39m dynamic_attr = _dynamic_imports.get(attr_name)\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dynamic_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getattr_migration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m package, module_name = dynamic_attr\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module_name == \u001b[33m'\u001b[39m\u001b[33m__module__\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp pc\\Desktop\\TunjiPaul\\working_with_rag\\myenv\\Lib\\site-packages\\pydantic\\_migration.py:304\u001b[39m, in \u001b[36mgetattr_migration.<locals>.wrapper\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m import_string(REDIRECT_TO_V1[import_path])\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m import_path == \u001b[33m'\u001b[39m\u001b[33mpydantic:BaseSettings\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\n\u001b[32m    305\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m`BaseSettings` has been moved to the `pydantic-settings` package. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSee https://docs.pydantic.dev/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/migration/#basesettings-has-moved-to-pydantic-settings \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    307\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfor more details.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;129;01min\u001b[39;00m REMOVED_IN_V2:\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` has been removed in V2.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mPydanticImportError\u001b[39m: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.12/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.12/u/import-error"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "print(f\"ChromaDB version: {chromadb.__version__}\")\n",
    "print(\"âœ… ChromaDB imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Create Chroma Client and Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: chromadb 0.3.23\n",
      "Uninstalling chromadb-0.3.23:\n",
      "  Successfully uninstalled chromadb-0.3.23\n",
      "Found existing installation: pydantic 1.10.26\n",
      "Uninstalling pydantic-1.10.26:\n",
      "  Successfully uninstalled pydantic-1.10.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hp pc\\Desktop\\TunjiPaul\\working_with_rag\\myenv\\Lib\\site-packages\\~ydantic'.\n",
      "You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-1.4.0-cp39-abi3-win_amd64.whl.metadata (7.3 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Using cached pybase64-1.4.3-cp314-cp314-win_amd64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (2.4.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (4.15.0)\n",
      "INFO: pip is looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.3.7-cp39-abi3-win_amd64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.3.6-cp39-abi3-win_amd64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.3.5-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.3.4-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.3.3-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.3.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.3.0-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "INFO: pip is still looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached chromadb-1.2.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.2.1-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.2.0-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.1.1-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.1.0-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached chromadb-1.0.21-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.0.20-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.0.19-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.0.18-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.0.17-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.0.16-cp39-abi3-win_amd64.whl.metadata (7.5 kB)\n",
      "  Using cached chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "  Using cached chromadb-1.0.13-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (7.4.2)\n",
      "  Using cached chromadb-1.0.12-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Using cached fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.11-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.10-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.9-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.8-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.7-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.6-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.5-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.4-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.3-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.2-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.0-cp39-abi3-win_amd64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (0.125.0)\n",
      "  Using cached chromadb-0.6.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.21-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.18-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.17-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.16-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.12-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.10-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.9-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting numpy<2.0.0,>=1.22.5 (from chromadb)\n",
      "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.5.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting chroma-hnswlib==0.7.5 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.5.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.5.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (2.32.5)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.3.tar.gz (31 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.5.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.23-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.22-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.21-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.20-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.19-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.18-py3-none-any.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-0.4.17-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.16-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-0.4.15-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.13-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-1.10.26-cp314-cp314-win_amd64.whl.metadata (156 kB)\n",
      "Collecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.11-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.10-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-0.4.9-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting chroma-hnswlib==0.7.2 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.2.tar.gz (31 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.8-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.7-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.4.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.4.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.4.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (2.3.3)\n",
      "Collecting chroma-hnswlib==0.7.1 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.1.tar.gz (30 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.4.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.3.29-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: hnswlib>=0.7 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (0.8.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (0.10.0)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (1.4.3)\n",
      "Collecting fastapi==0.85.1 (from chromadb)\n",
      "  Using cached fastapi-0.85.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.27-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-1.9.0-py3-none-any.whl.metadata (121 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.3.26-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.3.25-py3-none-any.whl.metadata (6.7 kB)\n",
      "  Using cached chromadb-0.3.23-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.2 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from chromadb) (5.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2025.11.12)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2.6.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2025.2)\n",
      "Requirement already satisfied: zstandard>=0.25.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.25.0)\n",
      "Requirement already satisfied: lz4>=4.4.5 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.4.5)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from starlette<0.51.0,>=0.40.0->fastapi>=0.95.2->chromadb) (4.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi>=0.95.2->chromadb) (3.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from pandas>=1.3->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from pandas>=1.3->chromadb) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from requests>=2.28->chromadb) (3.4.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (1.8.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (12.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.2.2->chromadb) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=2.2.2->chromadb) (2025.12.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from tqdm->sentence-transformers>=2.2.2->chromadb) (0.4.6)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (8.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.16.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.2.2->chromadb) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\hp pc\\desktop\\tunjipaul\\working_with_rag\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.6.0)\n",
      "Using cached chromadb-0.3.23-py3-none-any.whl (71 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Installing collected packages: pydantic, chromadb\n",
      "\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   ---------------------------------------- 0/2 [pydantic]\n",
      "   -------------------- ------------------- 1/2 [chromadb]\n",
      "   -------------------- ------------------- 1/2 [chromadb]\n",
      "   -------------------- ------------------- 1/2 [chromadb]\n",
      "   ---------------------------------------- 2/2 [chromadb]\n",
      "\n",
      "Successfully installed chromadb-0.3.23 pydantic-2.12.5\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall chromadb pydantic -y\n",
    "!pip install chromadb pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Chroma client (persistent storage)\n",
    "# # Note: ChromaDB 0.4.0+ uses PersistentClient instead of Client(Settings(...))\n",
    "# client = chromadb.Client(path=\"./chroma_db\")\n",
    "\n",
    "# # Create or get collection\n",
    "# collection = client.get_or_create_collection(\n",
    "#     name=\"my_documents\",\n",
    "#     metadata={\"description\": \"Sample document collection\"}\n",
    "# )\n",
    "\n",
    "# print(f\"âœ… Collection created: {collection.name}\")\n",
    "# print(f\"Current count: {collection.count()} documents\")\n",
    "# print(f\"ðŸ“ Data persisted to: ./chroma_db/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event client_start: capture() takes 1 positional argument but 3 were given\n",
      "Using embedded DuckDB with persistence: data will be stored in: ./chroma_db\n",
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f9a167fb-cbc6-4ac7-9250-323266f44c7c)')' thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Collection created: my_documents\n",
      "Current count: 0 documents\n",
      "ðŸ“ Data persisted to: ./chroma_db/\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Create Chroma client with persistent storage\n",
    "settings = Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    anonymized_telemetry=False\n",
    ")\n",
    "client = chromadb.Client(settings)\n",
    "\n",
    "# Create or get collection\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"my_documents\",\n",
    "    metadata={\"description\": \"Sample document collection\"}\n",
    ")\n",
    "\n",
    "print(f\"âœ… Collection created: {collection.name}\")\n",
    "print(f\"Current count: {collection.count()} documents\")\n",
    "print(f\"ðŸ“ Data persisted to: ./chroma_db/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Add Documents to Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event collection_add: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Added 5 documents to collection\n",
      "Total documents: 5\n"
     ]
    }
   ],
   "source": [
    "# Sample documents with metadata\n",
    "documents = [\n",
    "    \"Python is a versatile programming language used for web development and data science.\",\n",
    "    \"Machine learning models require large amounts of training data to perform well.\",\n",
    "    \"Neural networks are inspired by the structure of the human brain.\",\n",
    "    \"Natural language processing enables computers to understand human language.\",\n",
    "    \"Deep learning is a subset of machine learning using multi-layered neural networks.\"\n",
    "]\n",
    "\n",
    "# Metadata for each document\n",
    "metadatas = [\n",
    "    {\"category\": \"programming\", \"topic\": \"python\"},\n",
    "    {\"category\": \"AI\", \"topic\": \"machine learning\"},\n",
    "    {\"category\": \"AI\", \"topic\": \"neural networks\"},\n",
    "    {\"category\": \"AI\", \"topic\": \"NLP\"},\n",
    "    {\"category\": \"AI\", \"topic\": \"deep learning\"}\n",
    "]\n",
    "\n",
    "# IDs for each document\n",
    "ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "\n",
    "# Add to collection (Chroma handles embedding automatically!)\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "print(f\"âœ… Added {len(documents)} documents to collection\")\n",
    "print(f\"Total documents: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Chroma Magic\n",
    "\n",
    "Notice: We didn't manually generate embeddings! Chroma does it automatically using a default embedding model.\n",
    "\n",
    "**You can also specify your own embedding function (we'll see this later).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Query Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the collection\n",
    "results = collection.query(\n",
    "    query_texts=[\"What is artificial intelligence?\"],\n",
    "    n_results=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['doc_4', 'doc_3', 'doc_2']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Deep learning is a subset of machine learning using multi-layered neural networks.',\n",
       "   'Natural language processing enables computers to understand human language.',\n",
       "   'Neural networks are inspired by the structure of the human brain.']],\n",
       " 'metadatas': [[{'category': 'AI', 'topic': 'deep learning'},\n",
       "   {'category': 'AI', 'topic': 'NLP'},\n",
       "   {'category': 'AI', 'topic': 'neural networks'}]],\n",
       " 'distances': [[1.1504724025726318, 1.240823745727539, 1.2559771537780762]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is artificial intelligence?\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "1. (Distance: 1.1505)\n",
      "   Document: Deep learning is a subset of machine learning using multi-layered neural networks.\n",
      "   Metadata: {'category': 'AI', 'topic': 'deep learning'}\n",
      "\n",
      "2. (Distance: 1.2408)\n",
      "   Document: Natural language processing enables computers to understand human language.\n",
      "   Metadata: {'category': 'AI', 'topic': 'NLP'}\n",
      "\n",
      "3. (Distance: 1.2560)\n",
      "   Document: Neural networks are inspired by the structure of the human brain.\n",
      "   Metadata: {'category': 'AI', 'topic': 'neural networks'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the collection\n",
    "results = collection.query(\n",
    "    query_texts=[\"What is artificial intelligence?\"],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "print(\"Query: What is artificial intelligence?\\n\")\n",
    "print(\"Top 3 results:\\n\")\n",
    "\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results['documents'][0],\n",
    "    results['metadatas'][0],\n",
    "    results['distances'][0]\n",
    "), 1):\n",
    "    print(f\"{i}. (Distance: {distance:.4f})\")\n",
    "    print(f\"   Document: {doc}\")\n",
    "    print(f\"   Metadata: {metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (Distance: 1.1505)\n",
      "   Document: Deep learning is a subset of machine learning using multi-layered neural networks.\n",
      "   Metadata: {'category': 'AI', 'topic': 'deep learning'}\n",
      "\n",
      "2. (Distance: 1.2408)\n",
      "   Document: Natural language processing enables computers to understand human language.\n",
      "   Metadata: {'category': 'AI', 'topic': 'NLP'}\n",
      "\n",
      "3. (Distance: 1.2560)\n",
      "   Document: Neural networks are inspired by the structure of the human brain.\n",
      "   Metadata: {'category': 'AI', 'topic': 'neural networks'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results['documents'][0],\n",
    "    results['metadatas'][0],\n",
    "    results['distances'][0]\n",
    "), 1):\n",
    "    print(f\"{i}. (Distance: {distance:.4f})\")\n",
    "    print(f\"   Document: {doc}\")\n",
    "    print(f\"   Metadata: {metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Deep learning is a subset of machine learning using multi-layered neural networks.',\n",
       "  'Natural language processing enables computers to understand human language.',\n",
       "  'Neural networks are inspired by the structure of the human brain.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['documents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Filtering with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Tell me about AI (filtered by category='AI')\n",
      "\n",
      "Results:\n",
      "\n",
      "1. Deep learning is a subset of machine learning using multi-layered neural networks.\n",
      "   Category: AI, Topic: deep learning\n",
      "\n",
      "2. Natural language processing enables computers to understand human language.\n",
      "   Category: AI, Topic: NLP\n",
      "\n",
      "3. Neural networks are inspired by the structure of the human brain.\n",
      "   Category: AI, Topic: neural networks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query with metadata filter\n",
    "results = collection.query(\n",
    "    query_texts=[\"Tell me about AI\"],\n",
    "    n_results=3,\n",
    "    where={\"category\": \"AI\"}  # Only return AI documents\n",
    ")\n",
    "\n",
    "print(\"Query: Tell me about AI (filtered by category='AI')\\n\")\n",
    "print(\"Results:\\n\")\n",
    "\n",
    "for i, (doc, metadata) in enumerate(zip(\n",
    "    results['documents'][0],\n",
    "    results['metadatas'][0]\n",
    "), 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "    print(f\"   Category: {metadata['category']}, Topic: {metadata['topic']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is how the filtering is being done in real life:\n",
    "\n",
    "```\n",
    "detected_category = classify_user_query(query)  # AI â†’ returns \"AI\"\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=5,\n",
    "    where={\"category\": detected_category}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Using Custom Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event collection_add: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Collection with custom embeddings created\n",
      "Documents: 5\n"
     ]
    }
   ],
   "source": [
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Use sentence-transformers embedding function\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Create new collection with custom embedding function\n",
    "collection_custom = client.get_or_create_collection(\n",
    "    name=\"custom_embeddings\",\n",
    "    embedding_function=sentence_transformer_ef\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "collection_custom.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")\n",
    "\n",
    "print(f\"âœ… Collection with custom embeddings created\")\n",
    "print(f\"Documents: {collection_custom.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the collection\n",
    "results = collection_custom.query(\n",
    "    query_texts=[\"What is artificial intelligence?\"],\n",
    "    n_results=3,\n",
    "    include=[\"embeddings\", \"documents\", \"metadatas\", \"distances\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['doc_4', 'doc_3', 'doc_2']],\n",
       " 'embeddings': [[[-0.08768700808286667,\n",
       "    -0.026980997994542122,\n",
       "    0.06650561094284058,\n",
       "    -0.019901027902960777,\n",
       "    0.0198176521807909,\n",
       "    0.020893262699246407,\n",
       "    -0.05984418839216232,\n",
       "    -0.06580333411693573,\n",
       "    -0.059718355536460876,\n",
       "    -0.0970143973827362,\n",
       "    -0.0628766119480133,\n",
       "    -0.0560920313000679,\n",
       "    -0.0483679473400116,\n",
       "    -0.022331198677420616,\n",
       "    -0.051303353160619736,\n",
       "    -0.03572415933012962,\n",
       "    -0.022563615813851357,\n",
       "    0.01744166389107704,\n",
       "    -0.12321504950523376,\n",
       "    -0.05350054055452347,\n",
       "    0.06158197298645973,\n",
       "    0.014814444817602634,\n",
       "    -0.035895008593797684,\n",
       "    -0.034457072615623474,\n",
       "    0.02995811216533184,\n",
       "    0.01179139781743288,\n",
       "    -0.01980314403772354,\n",
       "    -0.0005557691911235452,\n",
       "    0.014717843383550644,\n",
       "    0.00994693860411644,\n",
       "    0.11747422069311142,\n",
       "    0.015478973276913166,\n",
       "    0.027272120118141174,\n",
       "    0.06985045224428177,\n",
       "    -0.04813646525144577,\n",
       "    0.043247442692518234,\n",
       "    -0.11698196828365326,\n",
       "    0.04454634711146355,\n",
       "    0.004245121031999588,\n",
       "    0.028020069003105164,\n",
       "    -0.07863671332597733,\n",
       "    0.02948872186243534,\n",
       "    -0.018446318805217743,\n",
       "    0.032328590750694275,\n",
       "    0.018283773213624954,\n",
       "    0.040156781673431396,\n",
       "    -0.05506010353565216,\n",
       "    -0.06808371096849442,\n",
       "    -0.0014910644385963678,\n",
       "    0.05742225423455238,\n",
       "    -0.039691656827926636,\n",
       "    -0.03499913215637207,\n",
       "    -0.04986758902668953,\n",
       "    0.06865472346544266,\n",
       "    0.040969375520944595,\n",
       "    -0.0028419175650924444,\n",
       "    0.03783451020717621,\n",
       "    0.011747533455491066,\n",
       "    -0.04680860415101051,\n",
       "    0.009975302964448929,\n",
       "    0.0007124047842808068,\n",
       "    -0.08045322448015213,\n",
       "    0.019064458087086678,\n",
       "    0.06741643697023392,\n",
       "    0.09932231158018112,\n",
       "    0.09759652614593506,\n",
       "    -0.08643466234207153,\n",
       "    0.05684640258550644,\n",
       "    0.031217217445373535,\n",
       "    -0.07398658990859985,\n",
       "    0.02877281792461872,\n",
       "    0.08808933198451996,\n",
       "    -0.011341193690896034,\n",
       "    -0.0038189683109521866,\n",
       "    0.02329987846314907,\n",
       "    -0.014989761635661125,\n",
       "    -0.002028510207310319,\n",
       "    0.007453626021742821,\n",
       "    0.09155167639255524,\n",
       "    -0.017480341717600822,\n",
       "    0.06311927735805511,\n",
       "    0.09289181977510452,\n",
       "    -0.06836315244436264,\n",
       "    0.01841123215854168,\n",
       "    0.1244814544916153,\n",
       "    -0.11544081568717957,\n",
       "    -0.020812906324863434,\n",
       "    -0.06182306259870529,\n",
       "    -0.0730636790394783,\n",
       "    -0.024451741948723793,\n",
       "    -0.0167185477912426,\n",
       "    -0.0625229999423027,\n",
       "    -0.02169479988515377,\n",
       "    -0.01733529567718506,\n",
       "    -0.015866311267018318,\n",
       "    -0.06682117283344269,\n",
       "    -0.029409777373075485,\n",
       "    -0.08148907870054245,\n",
       "    -0.024635178968310356,\n",
       "    -0.0022715721279382706,\n",
       "    -0.03138699010014534,\n",
       "    0.011121142655611038,\n",
       "    0.006923528388142586,\n",
       "    0.054779890924692154,\n",
       "    -0.003223447361961007,\n",
       "    -0.029140841215848923,\n",
       "    0.0710965022444725,\n",
       "    0.04998293146491051,\n",
       "    0.06915749609470367,\n",
       "    -0.11702712625265121,\n",
       "    -0.000693837646394968,\n",
       "    0.08157064020633698,\n",
       "    0.018667854368686676,\n",
       "    -0.017776086926460266,\n",
       "    0.002713111462071538,\n",
       "    -0.009139589965343475,\n",
       "    0.011271398514509201,\n",
       "    0.004606063477694988,\n",
       "    0.03329057618975639,\n",
       "    0.10803092271089554,\n",
       "    -0.09942147880792618,\n",
       "    -0.008005920797586441,\n",
       "    -0.02224709838628769,\n",
       "    -0.002579232444986701,\n",
       "    0.008001363836228848,\n",
       "    -0.03390806168317795,\n",
       "    -0.05312434211373329,\n",
       "    -5.457493795679039e-34,\n",
       "    -0.05669678375124931,\n",
       "    0.0025101604405790567,\n",
       "    -0.009282637387514114,\n",
       "    0.03511667624115944,\n",
       "    0.008065770380198956,\n",
       "    -0.04296332597732544,\n",
       "    -0.03917226567864418,\n",
       "    -0.003995764069259167,\n",
       "    -0.018053850159049034,\n",
       "    0.030342962592840195,\n",
       "    -0.07253548502922058,\n",
       "    0.04840691015124321,\n",
       "    -0.04932115599513054,\n",
       "    0.11739950627088547,\n",
       "    0.03778756409883499,\n",
       "    0.06093129143118858,\n",
       "    -0.031231872737407684,\n",
       "    0.06356516480445862,\n",
       "    0.07635977864265442,\n",
       "    -0.041798222810029984,\n",
       "    0.019126281142234802,\n",
       "    0.005431422498077154,\n",
       "    0.018200742080807686,\n",
       "    -0.028611978515982628,\n",
       "    -0.026121025905013084,\n",
       "    0.03398912027478218,\n",
       "    0.07404360175132751,\n",
       "    0.01717432215809822,\n",
       "    0.015469475649297237,\n",
       "    0.026149393990635872,\n",
       "    -0.026971345767378807,\n",
       "    0.01401068177074194,\n",
       "    -0.07662536948919296,\n",
       "    0.025644928216934204,\n",
       "    0.007362394127994776,\n",
       "    0.014385848306119442,\n",
       "    -0.03631450608372688,\n",
       "    0.026295233517885208,\n",
       "    0.05148787796497345,\n",
       "    -0.007214826997369528,\n",
       "    -0.03932081162929535,\n",
       "    -0.03357560932636261,\n",
       "    0.009144975803792477,\n",
       "    -0.03138113394379616,\n",
       "    -0.03778652474284172,\n",
       "    -0.05083172395825386,\n",
       "    0.021001366898417473,\n",
       "    -0.03739086911082268,\n",
       "    -0.04049217700958252,\n",
       "    -0.056958913803100586,\n",
       "    -0.004649441223591566,\n",
       "    -0.02937273494899273,\n",
       "    -0.0229438915848732,\n",
       "    -0.07314179837703705,\n",
       "    0.08485163748264313,\n",
       "    0.015674348920583725,\n",
       "    0.06791582703590393,\n",
       "    0.07239985466003418,\n",
       "    0.004830432124435902,\n",
       "    0.02675614506006241,\n",
       "    0.0429031066596508,\n",
       "    0.024921419098973274,\n",
       "    -0.06495814770460129,\n",
       "    0.0246902946382761,\n",
       "    0.04237409308552742,\n",
       "    0.10638532042503357,\n",
       "    0.047351449728012085,\n",
       "    0.04994179680943489,\n",
       "    0.0914369523525238,\n",
       "    0.017447376623749733,\n",
       "    -0.011172592639923096,\n",
       "    0.0350848026573658,\n",
       "    0.08542884141206741,\n",
       "    -0.04229750856757164,\n",
       "    -0.015501615591347218,\n",
       "    -0.0023741365876048803,\n",
       "    -0.033831480890512466,\n",
       "    -0.04618201032280922,\n",
       "    -0.006485133897513151,\n",
       "    0.10053994506597519,\n",
       "    -0.032285843044519424,\n",
       "    0.11728023737668991,\n",
       "    -0.07050573825836182,\n",
       "    -0.04312417656183243,\n",
       "    -0.004456695169210434,\n",
       "    0.017319558188319206,\n",
       "    -0.00022987859847489744,\n",
       "    -0.08595941960811615,\n",
       "    -0.02230917289853096,\n",
       "    0.0015605991939082742,\n",
       "    -0.10783205181360245,\n",
       "    -0.0027950708754360676,\n",
       "    0.008996421471238136,\n",
       "    -0.006515448912978172,\n",
       "    -0.03191976621747017,\n",
       "    -1.8448369972278218e-33,\n",
       "    -0.03714459389448166,\n",
       "    0.1048591136932373,\n",
       "    -0.08363955467939377,\n",
       "    0.06657510250806808,\n",
       "    0.05275220423936844,\n",
       "    -0.005174063611775637,\n",
       "    -0.08907387405633926,\n",
       "    -0.02724183350801468,\n",
       "    -0.06976883113384247,\n",
       "    0.05018043518066406,\n",
       "    -0.009860819205641747,\n",
       "    -0.022253183647990227,\n",
       "    -0.030562564730644226,\n",
       "    -0.0444059781730175,\n",
       "    0.011932434514164925,\n",
       "    0.045720960944890976,\n",
       "    -0.044715944677591324,\n",
       "    -0.026030749082565308,\n",
       "    -0.012709410861134529,\n",
       "    -0.04617362841963768,\n",
       "    -0.0008007026626728475,\n",
       "    0.011931062676012516,\n",
       "    -0.0141642726957798,\n",
       "    0.05614439398050308,\n",
       "    -0.013278000988066196,\n",
       "    -0.06254321336746216,\n",
       "    -0.0808597058057785,\n",
       "    0.03747773543000221,\n",
       "    0.050585485994815826,\n",
       "    -0.01418361347168684,\n",
       "    -0.0775083377957344,\n",
       "    -0.08179833739995956,\n",
       "    -0.04986009746789932,\n",
       "    0.0036433900240808725,\n",
       "    0.029199665412306786,\n",
       "    0.07884668558835983,\n",
       "    0.045712970197200775,\n",
       "    -0.026176530867815018,\n",
       "    0.004737656097859144,\n",
       "    -0.034104123711586,\n",
       "    0.021075675264000893,\n",
       "    0.015608887188136578,\n",
       "    -0.035292766988277435,\n",
       "    0.01864577829837799,\n",
       "    0.021154796704649925,\n",
       "    -0.03827662765979767,\n",
       "    -0.018195558339357376,\n",
       "    0.0008338895277120173,\n",
       "    0.01317452173680067,\n",
       "    -0.02765623666346073,\n",
       "    0.020748687908053398,\n",
       "    -0.03740137815475464,\n",
       "    -0.014286327175796032,\n",
       "    -0.013769722543656826,\n",
       "    -0.03632042184472084,\n",
       "    0.04539840668439865,\n",
       "    -0.010518673807382584,\n",
       "    -0.03545791283249855,\n",
       "    0.05407080799341202,\n",
       "    0.06175044924020767,\n",
       "    -0.08854479342699051,\n",
       "    -0.11404804140329361,\n",
       "    -0.04079103469848633,\n",
       "    0.030789127573370934,\n",
       "    -0.02161039039492607,\n",
       "    0.04578102007508278,\n",
       "    -0.027990682050585747,\n",
       "    0.0788039118051529,\n",
       "    -0.04879432171583176,\n",
       "    -0.025648586452007294,\n",
       "    0.0683140903711319,\n",
       "    0.05005482956767082,\n",
       "    -0.025648878887295723,\n",
       "    0.08132899552583694,\n",
       "    -0.10742907226085663,\n",
       "    -0.11403892934322357,\n",
       "    -0.00477337371557951,\n",
       "    -0.013141026720404625,\n",
       "    0.011423824355006218,\n",
       "    -0.013088050298392773,\n",
       "    0.07009447365999222,\n",
       "    -0.10951396077871323,\n",
       "    -0.0015451593790203333,\n",
       "    0.09293370693922043,\n",
       "    0.06323327124118805,\n",
       "    0.11142382025718689,\n",
       "    -0.006057306192815304,\n",
       "    0.0035523963160812855,\n",
       "    0.026279181241989136,\n",
       "    -0.07332827895879745,\n",
       "    -0.0012748579028993845,\n",
       "    0.0640692338347435,\n",
       "    -0.04720642790198326,\n",
       "    -0.026945864781737328,\n",
       "    -0.04330974072217941,\n",
       "    -2.1827442964195143e-08,\n",
       "    0.019748738035559654,\n",
       "    0.004501145798712969,\n",
       "    0.1362013816833496,\n",
       "    -0.09103301167488098,\n",
       "    0.07240643352270126,\n",
       "    -0.005667810328304768,\n",
       "    0.0251696165651083,\n",
       "    0.08997758477926254,\n",
       "    -0.04829717054963112,\n",
       "    0.054372139275074005,\n",
       "    0.07168459892272949,\n",
       "    -0.0014608083292841911,\n",
       "    -0.07955534011125565,\n",
       "    -0.024318523705005646,\n",
       "    0.005186075810343027,\n",
       "    0.05013047531247139,\n",
       "    0.01968223974108696,\n",
       "    0.02044730819761753,\n",
       "    0.03393831476569176,\n",
       "    0.004082561004906893,\n",
       "    0.11459574103355408,\n",
       "    0.024780504405498505,\n",
       "    -0.018535945564508438,\n",
       "    0.020298343151807785,\n",
       "    0.08306849747896194,\n",
       "    -0.06430571526288986,\n",
       "    -0.03069584257900715,\n",
       "    -0.004772403743118048,\n",
       "    0.00036771688610315323,\n",
       "    0.034883901476860046,\n",
       "    -0.04095246642827988,\n",
       "    0.03426907956600189,\n",
       "    -0.0016563601093366742,\n",
       "    -0.03561640530824661,\n",
       "    0.017124691978096962,\n",
       "    0.11835099011659622,\n",
       "    0.0645485371351242,\n",
       "    -0.027927936986088753,\n",
       "    0.004670933820307255,\n",
       "    -0.01009789016097784,\n",
       "    -0.07363355159759521,\n",
       "    0.0922454223036766,\n",
       "    -0.034883830696344376,\n",
       "    0.0029241214506328106,\n",
       "    -0.0025969413109123707,\n",
       "    0.008944042026996613,\n",
       "    0.013700343668460846,\n",
       "    -0.03092171624302864,\n",
       "    -0.007277988363057375,\n",
       "    0.05941971763968468,\n",
       "    0.04513382911682129,\n",
       "    0.0394936203956604,\n",
       "    0.05580805614590645,\n",
       "    0.106186144053936,\n",
       "    0.0021582830231636763,\n",
       "    -0.03520189970731735,\n",
       "    0.018873723223805428,\n",
       "    -0.1345967799425125,\n",
       "    0.01080494374036789,\n",
       "    0.058703385293483734,\n",
       "    0.026077380403876305,\n",
       "    0.03543119505047798,\n",
       "    -0.0064490921795368195,\n",
       "    0.011324329301714897],\n",
       "   [0.01383317168802023,\n",
       "    0.017584528774023056,\n",
       "    0.0978969931602478,\n",
       "    -0.06400614231824875,\n",
       "    0.021181810647249222,\n",
       "    -0.04221431910991669,\n",
       "    0.04960087314248085,\n",
       "    -0.011827167123556137,\n",
       "    0.08130312711000443,\n",
       "    0.010756582953035831,\n",
       "    -0.024793308228254318,\n",
       "    -0.014463892206549644,\n",
       "    0.028198346495628357,\n",
       "    -0.03761992231011391,\n",
       "    0.11492067575454712,\n",
       "    -0.00038572121411561966,\n",
       "    -0.04448852315545082,\n",
       "    -0.01994958333671093,\n",
       "    -0.09090609848499298,\n",
       "    -0.06491492688655853,\n",
       "    0.041540540754795074,\n",
       "    0.033507462590932846,\n",
       "    -0.05105394497513771,\n",
       "    -0.029515238478779793,\n",
       "    -0.000330415612552315,\n",
       "    0.09108725190162659,\n",
       "    -0.05363855138421059,\n",
       "    -0.07130127400159836,\n",
       "    0.1154177337884903,\n",
       "    -0.0038705591578036547,\n",
       "    0.04897940903902054,\n",
       "    0.012997529469430447,\n",
       "    0.1372162103652954,\n",
       "    0.11035831272602081,\n",
       "    -0.05338854342699051,\n",
       "    0.01376016903668642,\n",
       "    -0.02100614830851555,\n",
       "    0.033528346568346024,\n",
       "    -0.0032853265292942524,\n",
       "    -0.030433932319283485,\n",
       "    -0.07699597626924515,\n",
       "    -0.027915161103010178,\n",
       "    0.03190585970878601,\n",
       "    0.018295511603355408,\n",
       "    0.11761682480573654,\n",
       "    0.04042994976043701,\n",
       "    -0.10731521993875504,\n",
       "    0.012575524859130383,\n",
       "    -0.032390084117650986,\n",
       "    0.023366408422589302,\n",
       "    -0.13443343341350555,\n",
       "    0.028396207839250565,\n",
       "    0.02552337571978569,\n",
       "    0.062106311321258545,\n",
       "    -0.06207665801048279,\n",
       "    0.1252460926771164,\n",
       "    0.007562519516795874,\n",
       "    -0.010275294072926044,\n",
       "    0.014534110203385353,\n",
       "    -0.04298175498843193,\n",
       "    -0.0551062636077404,\n",
       "    -0.1248549371957779,\n",
       "    -0.018405737355351448,\n",
       "    0.07993727922439575,\n",
       "    0.027657680213451385,\n",
       "    0.003998998086899519,\n",
       "    -0.03275522589683533,\n",
       "    -0.01608472317457199,\n",
       "    -0.0073676095344126225,\n",
       "    -0.035087913274765015,\n",
       "    5.137224798090756e-05,\n",
       "    0.08769696950912476,\n",
       "    0.03462252765893936,\n",
       "    0.06928755342960358,\n",
       "    -0.020685510709881783,\n",
       "    0.03207651898264885,\n",
       "    -0.04992692917585373,\n",
       "    -0.04190758988261223,\n",
       "    0.07970881462097168,\n",
       "    -0.02557339519262314,\n",
       "    0.04523630440235138,\n",
       "    0.02523854933679104,\n",
       "    0.06111866608262062,\n",
       "    0.061151545494794846,\n",
       "    0.051849622279405594,\n",
       "    -0.007284658960998058,\n",
       "    -0.030876288190484047,\n",
       "    -0.029443757608532906,\n",
       "    -0.04629705101251602,\n",
       "    0.03089083731174469,\n",
       "    0.0056410906836390495,\n",
       "    -0.16315679252147675,\n",
       "    0.029227308928966522,\n",
       "    0.00948458444327116,\n",
       "    -0.024713007733225822,\n",
       "    -0.021514950320124626,\n",
       "    0.004502099007368088,\n",
       "    -0.050501830875873566,\n",
       "    0.05098686367273331,\n",
       "    0.020416123792529106,\n",
       "    0.031759846955537796,\n",
       "    -0.009869007393717766,\n",
       "    -0.0029492895118892193,\n",
       "    0.0021864951122552156,\n",
       "    -0.049133557826280594,\n",
       "    -0.024652700871229172,\n",
       "    0.00879017636179924,\n",
       "    0.00907310750335455,\n",
       "    0.05284537002444267,\n",
       "    -0.08843249082565308,\n",
       "    -0.03515445441007614,\n",
       "    0.0060201045125722885,\n",
       "    -0.04567793011665344,\n",
       "    0.02546389028429985,\n",
       "    0.006562422029674053,\n",
       "    -0.015869522467255592,\n",
       "    0.013346408493816853,\n",
       "    0.029393870383501053,\n",
       "    0.08781647682189941,\n",
       "    -0.0355110764503479,\n",
       "    -0.04811576008796692,\n",
       "    0.07949993759393692,\n",
       "    -0.029427025467157364,\n",
       "    0.009715189225971699,\n",
       "    0.08959464728832245,\n",
       "    -0.09741175174713135,\n",
       "    0.05234155058860779,\n",
       "    -4.259464391632023e-33,\n",
       "    -0.001104583963751793,\n",
       "    -0.0413581058382988,\n",
       "    -0.0038065637927502394,\n",
       "    0.010427290573716164,\n",
       "    0.025996677577495575,\n",
       "    0.040589116513729095,\n",
       "    -0.05830606073141098,\n",
       "    -0.07979539036750793,\n",
       "    0.01622834987938404,\n",
       "    0.04456563666462898,\n",
       "    0.05557084456086159,\n",
       "    0.007460873108357191,\n",
       "    0.006814002525061369,\n",
       "    0.026081619784235954,\n",
       "    0.01097390241920948,\n",
       "    0.04461248591542244,\n",
       "    -0.020702887326478958,\n",
       "    0.09650537371635437,\n",
       "    -0.039691559970378876,\n",
       "    -0.04803254082798958,\n",
       "    0.014894459396600723,\n",
       "    0.01065872423350811,\n",
       "    0.012436321005225182,\n",
       "    -0.004958289209753275,\n",
       "    -0.05359697341918945,\n",
       "    0.021637970581650734,\n",
       "    0.005808846093714237,\n",
       "    -0.08053242415189743,\n",
       "    0.06542439758777618,\n",
       "    -0.0071059041656553745,\n",
       "    -0.055424436926841736,\n",
       "    0.03318927809596062,\n",
       "    -0.07835599035024643,\n",
       "    -0.03326845541596413,\n",
       "    0.026279525831341743,\n",
       "    -0.10213042050600052,\n",
       "    0.07823385298252106,\n",
       "    -0.04506403207778931,\n",
       "    0.020568113774061203,\n",
       "    -0.040955983102321625,\n",
       "    -0.09427789598703384,\n",
       "    0.04769822955131531,\n",
       "    0.022875957190990448,\n",
       "    -0.001992548117414117,\n",
       "    -0.006363856606185436,\n",
       "    0.044024862349033356,\n",
       "    0.01852579042315483,\n",
       "    0.05598288029432297,\n",
       "    0.0038445303216576576,\n",
       "    -0.039332129061222076,\n",
       "    0.016482677310705185,\n",
       "    0.014520197175443172,\n",
       "    0.06433327496051788,\n",
       "    0.024237437173724174,\n",
       "    0.09670165926218033,\n",
       "    0.053567636758089066,\n",
       "    0.07495449483394623,\n",
       "    -0.021842414513230324,\n",
       "    -0.004836516920477152,\n",
       "    -0.001009950996376574,\n",
       "    0.04748367518186569,\n",
       "    0.007540067192167044,\n",
       "    0.06504517048597336,\n",
       "    0.018095465376973152,\n",
       "    0.03311033174395561,\n",
       "    0.004056855570524931,\n",
       "    0.035853225737810135,\n",
       "    0.051374513655900955,\n",
       "    0.0078415647149086,\n",
       "    0.015472612343728542,\n",
       "    -0.07757366448640823,\n",
       "    0.01738910563290119,\n",
       "    -0.02306092344224453,\n",
       "    -0.001887475955300033,\n",
       "    0.02813507616519928,\n",
       "    -0.02207183465361595,\n",
       "    0.04342467710375786,\n",
       "    -0.05883060023188591,\n",
       "    -0.014188039116561413,\n",
       "    0.06804563105106354,\n",
       "    -0.07824943959712982,\n",
       "    -0.12948058545589447,\n",
       "    0.06686221808195114,\n",
       "    -0.02494407817721367,\n",
       "    0.03882451355457306,\n",
       "    -0.0161940585821867,\n",
       "    0.020984096452593803,\n",
       "    -0.05136020854115486,\n",
       "    0.025405775755643845,\n",
       "    -0.05187170207500458,\n",
       "    0.028150388970971107,\n",
       "    -0.021048810333013535,\n",
       "    -0.07349619269371033,\n",
       "    0.05084864795207977,\n",
       "    -0.07104574143886566,\n",
       "    2.7734288615644652e-33,\n",
       "    -0.09542056918144226,\n",
       "    -0.03480837121605873,\n",
       "    -0.103379026055336,\n",
       "    0.0431203693151474,\n",
       "    -0.057684045284986496,\n",
       "    -0.08033960312604904,\n",
       "    0.043185025453567505,\n",
       "    -0.07429664582014084,\n",
       "    0.027528923004865646,\n",
       "    -0.04248451068997383,\n",
       "    -0.02780446782708168,\n",
       "    0.04853488504886627,\n",
       "    0.028167689219117165,\n",
       "    0.04381640627980232,\n",
       "    0.050481680780649185,\n",
       "    -0.009735937230288982,\n",
       "    0.004783115349709988,\n",
       "    0.038804568350315094,\n",
       "    -0.010745554231107235,\n",
       "    0.053542304784059525,\n",
       "    -0.018575016409158707,\n",
       "    0.058340590447187424,\n",
       "    -0.0961364284157753,\n",
       "    0.0044113569892942905,\n",
       "    0.056980639696121216,\n",
       "    0.03719377890229225,\n",
       "    -0.055548783391714096,\n",
       "    -0.007051479537039995,\n",
       "    -0.02549465373158455,\n",
       "    0.04112148657441139,\n",
       "    -0.009488467127084732,\n",
       "    -0.005004871636629105,\n",
       "    -0.05251779779791832,\n",
       "    0.017313014715909958,\n",
       "    0.041200317442417145,\n",
       "    -0.06820229440927505,\n",
       "    -0.0007045557140372694,\n",
       "    -0.01037959661334753,\n",
       "    -0.002179553732275963,\n",
       "    -0.02002444863319397,\n",
       "    0.09454778581857681,\n",
       "    0.07360843569040298,\n",
       "    -0.051164232194423676,\n",
       "    0.011466292664408684,\n",
       "    -0.00795767828822136,\n",
       "    0.005767481401562691,\n",
       "    -0.02872404083609581,\n",
       "    -0.011996748857200146,\n",
       "    -0.029791200533509254,\n",
       "    0.032960016280412674,\n",
       "    0.11666276305913925,\n",
       "    -0.013629053719341755,\n",
       "    0.009970375336706638,\n",
       "    -0.0480034239590168,\n",
       "    -0.03464158996939659,\n",
       "    -0.03645613417029381,\n",
       "    0.03181637078523636,\n",
       "    -0.10869286209344864,\n",
       "    -0.020121967419981956,\n",
       "    0.0179160013794899,\n",
       "    -0.09525059163570404,\n",
       "    0.019418759271502495,\n",
       "    0.05883651226758957,\n",
       "    -0.03164099529385567,\n",
       "    -0.033317312598228455,\n",
       "    -0.01261700689792633,\n",
       "    -0.046516913920640945,\n",
       "    0.07567526400089264,\n",
       "    -0.04803214222192764,\n",
       "    -0.07359465956687927,\n",
       "    0.04589974135160446,\n",
       "    0.050672464072704315,\n",
       "    -0.06547947227954865,\n",
       "    0.06733320653438568,\n",
       "    -0.04242151975631714,\n",
       "    0.05342206358909607,\n",
       "    -0.005285114515572786,\n",
       "    -0.043552253395318985,\n",
       "    -0.03196290135383606,\n",
       "    -0.004839058965444565,\n",
       "    0.02839524857699871,\n",
       "    0.007078185211867094,\n",
       "    0.02464013360440731,\n",
       "    0.025231117382645607,\n",
       "    0.0371498167514801,\n",
       "    0.06989424675703049,\n",
       "    -0.01575160212814808,\n",
       "    -0.007910291664302349,\n",
       "    -0.0020702879410237074,\n",
       "    -0.05226775258779526,\n",
       "    -0.019019246101379395,\n",
       "    -0.00939769297838211,\n",
       "    -0.013070068322122097,\n",
       "    0.11325022578239441,\n",
       "    -0.14484786987304688,\n",
       "    -1.6401459745907232e-08,\n",
       "    -0.08777774125337601,\n",
       "    -0.042424269020557404,\n",
       "    -0.012220476754009724,\n",
       "    0.005223671440035105,\n",
       "    0.06755173951387405,\n",
       "    0.017794551327824593,\n",
       "    -0.08051321655511856,\n",
       "    0.048940207809209824,\n",
       "    -0.06735729426145554,\n",
       "    -0.07044489681720734,\n",
       "    0.009742876514792442,\n",
       "    -0.009657708927989006,\n",
       "    -0.0516878217458725,\n",
       "    0.015343706123530865,\n",
       "    0.07473382353782654,\n",
       "    0.0653146505355835,\n",
       "    0.030407126992940903,\n",
       "    -0.013403951190412045,\n",
       "    -0.022554701194167137,\n",
       "    -0.042806271463632584,\n",
       "    0.10692793875932693,\n",
       "    -0.005026363767683506,\n",
       "    -0.062196873128414154,\n",
       "    0.128493994474411,\n",
       "    -0.004490162245929241,\n",
       "    -0.0016278732800856233,\n",
       "    -0.05685890465974808,\n",
       "    0.053579945117235184,\n",
       "    0.010401167906820774,\n",
       "    -0.018257135525345802,\n",
       "    0.06686864793300629,\n",
       "    0.008491051383316517,\n",
       "    -0.022335859015583992,\n",
       "    0.024556109681725502,\n",
       "    0.12195972353219986,\n",
       "    0.08063440769910812,\n",
       "    0.0051751937717199326,\n",
       "    -0.07885107398033142,\n",
       "    0.03071490302681923,\n",
       "    -0.0509854331612587,\n",
       "    0.0022735740058124065,\n",
       "    0.07878169417381287,\n",
       "    -0.06224159523844719,\n",
       "    0.01534846518188715,\n",
       "    0.028504211455583572,\n",
       "    -0.04181705787777901,\n",
       "    -0.005679465364664793,\n",
       "    -0.09163607656955719,\n",
       "    -0.007660252507776022,\n",
       "    0.004446748178452253,\n",
       "    -0.0010288533521816134,\n",
       "    -0.00642786081880331,\n",
       "    0.04385243356227875,\n",
       "    0.07385656982660294,\n",
       "    0.05024529621005058,\n",
       "    -0.06570294499397278,\n",
       "    0.009905480779707432,\n",
       "    -0.014075834304094315,\n",
       "    0.012209614738821983,\n",
       "    0.016003062948584557,\n",
       "    -0.026934538036584854,\n",
       "    0.08880782127380371,\n",
       "    0.04175100848078728,\n",
       "    -0.0565590001642704],\n",
       "   [-0.0656045526266098,\n",
       "    -0.08392675966024399,\n",
       "    0.05001440644264221,\n",
       "    -0.029309866949915886,\n",
       "    -0.013358531519770622,\n",
       "    0.007439883891493082,\n",
       "    0.0056749205105006695,\n",
       "    -0.007654659915715456,\n",
       "    0.11789046972990036,\n",
       "    -0.017608268186450005,\n",
       "    -0.01536409929394722,\n",
       "    0.06299400329589844,\n",
       "    0.001135127036832273,\n",
       "    -0.024850428104400635,\n",
       "    -0.059022556990385056,\n",
       "    -0.07550808042287827,\n",
       "    -0.09921878576278687,\n",
       "    0.0321972630918026,\n",
       "    -0.056226592510938644,\n",
       "    0.03604226931929588,\n",
       "    -0.0005858291406184435,\n",
       "    0.0384269654750824,\n",
       "    -0.03623540699481964,\n",
       "    0.008640064857900143,\n",
       "    -0.06255163997411728,\n",
       "    0.09247124195098877,\n",
       "    0.0016392008401453495,\n",
       "    0.004783276002854109,\n",
       "    0.021384727209806442,\n",
       "    0.001675141858868301,\n",
       "    0.12965543568134308,\n",
       "    -0.03463182970881462,\n",
       "    0.02159060724079609,\n",
       "    0.018937356770038605,\n",
       "    -0.06018904969096184,\n",
       "    0.04011843726038933,\n",
       "    -0.040473345667123795,\n",
       "    -0.029531095176935196,\n",
       "    0.0009322382975369692,\n",
       "    0.007060256786644459,\n",
       "    -0.051892831921577454,\n",
       "    -0.007754362653940916,\n",
       "    -0.004573015496134758,\n",
       "    0.05373627319931984,\n",
       "    0.0834813341498375,\n",
       "    0.06554970890283585,\n",
       "    -0.03382475674152374,\n",
       "    -0.0825842022895813,\n",
       "    -0.03297901898622513,\n",
       "    -0.023498525843024254,\n",
       "    -0.06239857152104378,\n",
       "    -0.009732570499181747,\n",
       "    -0.02768665924668312,\n",
       "    0.007121805567294359,\n",
       "    0.06230923905968666,\n",
       "    0.08407942950725555,\n",
       "    -0.03674499690532684,\n",
       "    0.04151729866862297,\n",
       "    -0.056720878928899765,\n",
       "    0.0005760252824984491,\n",
       "    0.0008850459707900882,\n",
       "    -0.022254448384046555,\n",
       "    -0.021617494523525238,\n",
       "    0.0407077856361866,\n",
       "    0.10264518857002258,\n",
       "    0.11057662963867188,\n",
       "    -0.029598258435726166,\n",
       "    -0.019389791414141655,\n",
       "    0.009174562990665436,\n",
       "    -0.045082706958055496,\n",
       "    0.11249400675296783,\n",
       "    0.028482025489211082,\n",
       "    -0.019644448533654213,\n",
       "    0.002290507545694709,\n",
       "    0.049257442355155945,\n",
       "    0.04943595826625824,\n",
       "    0.010342685505747795,\n",
       "    0.00833841785788536,\n",
       "    0.028355661779642105,\n",
       "    -0.05402969941496849,\n",
       "    -0.0026437570340931416,\n",
       "    -0.004512710962444544,\n",
       "    0.04168124124407768,\n",
       "    0.038068175315856934,\n",
       "    0.04914659261703491,\n",
       "    0.026439368724822998,\n",
       "    0.010009185411036015,\n",
       "    0.02252599410712719,\n",
       "    -0.04033322632312775,\n",
       "    0.0025505300145596266,\n",
       "    -0.017745550721883774,\n",
       "    -0.04661281406879425,\n",
       "    -0.07645218074321747,\n",
       "    -0.07856474816799164,\n",
       "    -0.02751387096941471,\n",
       "    -0.0009327513398602605,\n",
       "    -0.014368823729455471,\n",
       "    -0.011480429209768772,\n",
       "    0.030290426686406136,\n",
       "    0.025648271664977074,\n",
       "    -0.001407103263773024,\n",
       "    -0.021160634234547615,\n",
       "    0.0123229855671525,\n",
       "    0.02776576392352581,\n",
       "    0.09782719612121582,\n",
       "    0.011573492549359798,\n",
       "    0.08565469086170197,\n",
       "    0.013759156689047813,\n",
       "    0.08559492230415344,\n",
       "    -0.08361803740262985,\n",
       "    -0.06894750148057938,\n",
       "    0.02620902843773365,\n",
       "    -0.060099080204963684,\n",
       "    0.0040825712494552135,\n",
       "    0.026538502424955368,\n",
       "    -0.0957428514957428,\n",
       "    -0.035790544003248215,\n",
       "    0.02292674034833908,\n",
       "    0.05876997113227844,\n",
       "    0.01123853400349617,\n",
       "    -0.0001642621064092964,\n",
       "    0.010689064860343933,\n",
       "    -0.05924849212169647,\n",
       "    -0.024281103163957596,\n",
       "    -0.00841729436069727,\n",
       "    -0.07675663381814957,\n",
       "    -0.15712220966815948,\n",
       "    -4.5706846025358856e-33,\n",
       "    -0.04331982880830765,\n",
       "    -0.008943308144807816,\n",
       "    0.07654541730880737,\n",
       "    -0.009875427931547165,\n",
       "    0.038144201040267944,\n",
       "    -0.039510536938905716,\n",
       "    0.043807126581668854,\n",
       "    -0.06868089735507965,\n",
       "    0.09397841989994049,\n",
       "    0.00447893189266324,\n",
       "    -0.13960565626621246,\n",
       "    0.013820221647620201,\n",
       "    -0.01728004589676857,\n",
       "    0.14231528341770172,\n",
       "    0.013539064675569534,\n",
       "    -0.07305335998535156,\n",
       "    -0.031191518530249596,\n",
       "    -0.015324470587074757,\n",
       "    -0.014656657353043556,\n",
       "    -0.08969070762395859,\n",
       "    0.036463841795921326,\n",
       "    -0.011044626124203205,\n",
       "    0.038118213415145874,\n",
       "    -0.033736761659383774,\n",
       "    -0.08085165172815323,\n",
       "    -0.030749386176466942,\n",
       "    -0.06687990576028824,\n",
       "    0.02591465786099434,\n",
       "    -0.07912064343690872,\n",
       "    0.018379993736743927,\n",
       "    -0.03153856471180916,\n",
       "    0.05288831889629364,\n",
       "    -0.068269282579422,\n",
       "    -0.04020434990525246,\n",
       "    -0.006040163803845644,\n",
       "    0.031672410666942596,\n",
       "    0.09619377553462982,\n",
       "    0.014690936543047428,\n",
       "    0.025298068299889565,\n",
       "    0.017056763172149658,\n",
       "    0.030555853620171547,\n",
       "    0.005309645086526871,\n",
       "    0.02270491048693657,\n",
       "    -0.013324913568794727,\n",
       "    0.04419372230768204,\n",
       "    0.03157033771276474,\n",
       "    -0.019537467509508133,\n",
       "    -0.03405698388814926,\n",
       "    0.011665118858218193,\n",
       "    -0.07255809754133224,\n",
       "    -0.027165791019797325,\n",
       "    0.01699003390967846,\n",
       "    0.05138949677348137,\n",
       "    -0.06296001374721527,\n",
       "    0.08036557585000992,\n",
       "    0.02085808478295803,\n",
       "    -0.019765961915254593,\n",
       "    0.0650482028722763,\n",
       "    0.008582694455981255,\n",
       "    0.049533627927303314,\n",
       "    -0.009994062595069408,\n",
       "    0.017387133091688156,\n",
       "    -0.011643732897937298,\n",
       "    0.03709237650036812,\n",
       "    0.08972631394863129,\n",
       "    0.07372140139341354,\n",
       "    -0.044095735996961594,\n",
       "    -0.0417298898100853,\n",
       "    0.042724497616291046,\n",
       "    0.03403376042842865,\n",
       "    0.036638043820858,\n",
       "    0.0840524360537529,\n",
       "    -0.0572366826236248,\n",
       "    -0.027641305699944496,\n",
       "    -0.04432159662246704,\n",
       "    2.1290323275025003e-05,\n",
       "    -0.02114231325685978,\n",
       "    -0.028451835736632347,\n",
       "    -0.06926656514406204,\n",
       "    0.0562998503446579,\n",
       "    -0.05587353557348251,\n",
       "    -0.0014477645745500922,\n",
       "    -0.05483242869377136,\n",
       "    0.004887380637228489,\n",
       "    0.005091005936264992,\n",
       "    0.06929047405719757,\n",
       "    0.08737215399742126,\n",
       "    -0.06962265819311142,\n",
       "    -0.04781182110309601,\n",
       "    -0.01277125347405672,\n",
       "    -0.013064287602901459,\n",
       "    -0.03369608148932457,\n",
       "    0.12458785623311996,\n",
       "    -0.04103932902216911,\n",
       "    -0.03926782310009003,\n",
       "    2.5207120861460664e-33,\n",
       "    -0.09286652505397797,\n",
       "    0.004532355349510908,\n",
       "    -0.05003649368882179,\n",
       "    -0.03082188218832016,\n",
       "    0.006328084040433168,\n",
       "    0.04503203183412552,\n",
       "    -0.005458454135805368,\n",
       "    0.0013365219347178936,\n",
       "    -0.08040966093540192,\n",
       "    0.10606416314840317,\n",
       "    0.04223586991429329,\n",
       "    -0.004638480953872204,\n",
       "    0.004781146999448538,\n",
       "    -0.0064403340220451355,\n",
       "    0.02918270044028759,\n",
       "    -0.04685984551906586,\n",
       "    -0.022070420905947685,\n",
       "    -0.03776796534657478,\n",
       "    0.08072638511657715,\n",
       "    -0.08406911045312881,\n",
       "    0.013748613186180592,\n",
       "    0.08204632252454758,\n",
       "    -0.0990215316414833,\n",
       "    -0.025721414014697075,\n",
       "    0.014548219740390778,\n",
       "    0.018618764355778694,\n",
       "    -0.09243959188461304,\n",
       "    0.06224588677287102,\n",
       "    0.00997950416058302,\n",
       "    0.0662357285618782,\n",
       "    -0.09171172231435776,\n",
       "    -0.04365198314189911,\n",
       "    -0.0459260419011116,\n",
       "    0.010076825506985188,\n",
       "    0.04792293161153793,\n",
       "    0.09840705245733261,\n",
       "    -0.03360944241285324,\n",
       "    0.0029885389376431704,\n",
       "    -0.022807033732533455,\n",
       "    -0.07259730249643326,\n",
       "    -0.011185850948095322,\n",
       "    0.02294079028069973,\n",
       "    0.030840428546071053,\n",
       "    -0.03502247855067253,\n",
       "    0.044938091188669205,\n",
       "    -0.0681571438908577,\n",
       "    0.022432029247283936,\n",
       "    0.00587920006364584,\n",
       "    -0.12119919061660767,\n",
       "    0.04344963654875755,\n",
       "    0.029202137142419815,\n",
       "    0.025832822546362877,\n",
       "    -0.07383333891630173,\n",
       "    -0.09390489012002945,\n",
       "    -0.05470620095729828,\n",
       "    0.03768768534064293,\n",
       "    0.02976750023663044,\n",
       "    -0.04436275362968445,\n",
       "    0.13644911348819733,\n",
       "    -0.006485724356025457,\n",
       "    -0.046461813151836395,\n",
       "    -0.11124259233474731,\n",
       "    0.0136867118999362,\n",
       "    -0.0022833463735878468,\n",
       "    -0.05418829619884491,\n",
       "    0.039198532700538635,\n",
       "    0.011458332650363445,\n",
       "    0.06834382563829422,\n",
       "    0.028087174519896507,\n",
       "    -0.055092934519052505,\n",
       "    0.014315949752926826,\n",
       "    0.04772234335541725,\n",
       "    0.02828272059559822,\n",
       "    0.10161394625902176,\n",
       "    -0.06641072034835815,\n",
       "    -0.07526363432407379,\n",
       "    -0.024476734921336174,\n",
       "    0.028837408870458603,\n",
       "    -0.0028293945360928774,\n",
       "    -0.05600275099277496,\n",
       "    0.02954818308353424,\n",
       "    -0.05914713069796562,\n",
       "    -0.017217762768268585,\n",
       "    0.04210710898041725,\n",
       "    0.06677815318107605,\n",
       "    0.05973915383219719,\n",
       "    -0.004018452949821949,\n",
       "    -0.008971345610916615,\n",
       "    0.038456887006759644,\n",
       "    0.006804205942898989,\n",
       "    0.016556642949581146,\n",
       "    0.026720361784100533,\n",
       "    0.008215442299842834,\n",
       "    0.0641772598028183,\n",
       "    -0.06304150074720383,\n",
       "    -1.8259548539845127e-08,\n",
       "    -0.059932414442300797,\n",
       "    0.017713099718093872,\n",
       "    0.08165014535188675,\n",
       "    0.07399877905845642,\n",
       "    0.08533015847206116,\n",
       "    -0.0160618107765913,\n",
       "    0.08511797338724136,\n",
       "    0.024768149480223656,\n",
       "    -0.0636940747499466,\n",
       "    -0.06097923591732979,\n",
       "    0.06301311403512955,\n",
       "    0.01751297526061535,\n",
       "    -0.040111225098371506,\n",
       "    0.02494337223470211,\n",
       "    0.03621235489845276,\n",
       "    0.03008722886443138,\n",
       "    0.020884739235043526,\n",
       "    0.004445960279554129,\n",
       "    0.023261552676558495,\n",
       "    0.0014058344531804323,\n",
       "    0.06559421867132187,\n",
       "    0.02107536420226097,\n",
       "    -0.05254225805401802,\n",
       "    0.038690946996212006,\n",
       "    0.07689471542835236,\n",
       "    -0.04066190496087074,\n",
       "    -0.07244137674570084,\n",
       "    0.026771802455186844,\n",
       "    -0.0818452462553978,\n",
       "    0.03175162151455879,\n",
       "    0.034225836396217346,\n",
       "    0.03577063977718353,\n",
       "    0.0031561332289129496,\n",
       "    0.007743770722299814,\n",
       "    0.054668109863996506,\n",
       "    0.037950918078422546,\n",
       "    0.027702627703547478,\n",
       "    -0.024481886997818947,\n",
       "    -0.11156528443098068,\n",
       "    -0.06263063848018646,\n",
       "    -0.029235778376460075,\n",
       "    0.0008531772182323039,\n",
       "    0.05029252916574478,\n",
       "    0.009235532023012638,\n",
       "    0.028374992311000824,\n",
       "    -0.01046810857951641,\n",
       "    0.05574621260166168,\n",
       "    -0.04158087819814682,\n",
       "    0.023394770920276642,\n",
       "    -0.011481700465083122,\n",
       "    -0.011972542852163315,\n",
       "    0.026191802695393562,\n",
       "    -0.007362255826592445,\n",
       "    -0.021980583667755127,\n",
       "    -0.0009876369731500745,\n",
       "    -0.053990527987480164,\n",
       "    0.0018417708342894912,\n",
       "    -0.06106385961174965,\n",
       "    -0.07668476551771164,\n",
       "    0.02691163867712021,\n",
       "    0.01680731400847435,\n",
       "    0.16255855560302734,\n",
       "    0.05264853686094284,\n",
       "    -0.06086662411689758]]],\n",
       " 'documents': [['Deep learning is a subset of machine learning using multi-layered neural networks.',\n",
       "   'Natural language processing enables computers to understand human language.',\n",
       "   'Neural networks are inspired by the structure of the human brain.']],\n",
       " 'metadatas': [[{'category': 'AI', 'topic': 'deep learning'},\n",
       "   {'category': 'AI', 'topic': 'NLP'},\n",
       "   {'category': 'AI', 'topic': 'neural networks'}]],\n",
       " 'distances': [[1.1504724025726318, 1.240823745727539, 1.2559771537780762]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is artificial intelligence?\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "1. (Distance: 1.1505)\n",
      "   Document: Deep learning is a subset of machine learning using multi-layered neural networks.\n",
      "   Metadata: {'category': 'AI', 'topic': 'deep learning'}\n",
      "\n",
      "2. (Distance: 1.2408)\n",
      "   Document: Natural language processing enables computers to understand human language.\n",
      "   Metadata: {'category': 'AI', 'topic': 'NLP'}\n",
      "\n",
      "3. (Distance: 1.2560)\n",
      "   Document: Neural networks are inspired by the structure of the human brain.\n",
      "   Metadata: {'category': 'AI', 'topic': 'neural networks'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the collection\n",
    "results = collection_custom.query(\n",
    "    query_texts=[\"What is artificial intelligence?\"],\n",
    "    n_results=3,\n",
    "    include=[\"embeddings\", \"documents\", \"metadatas\", \"distances\"]\n",
    ")\n",
    "\n",
    "print(\"Query: What is artificial intelligence?\\n\")\n",
    "print(\"Top 3 results:\\n\")\n",
    "\n",
    "for i, (doc, metadata, distance) in enumerate(zip(\n",
    "    results['documents'][0],\n",
    "    results['metadatas'][0],\n",
    "    results['distances'][0]\n",
    "), 1):\n",
    "    print(f\"{i}. (Distance: {distance:.4f})\")\n",
    "    print(f\"   Document: {doc}\")\n",
    "    print(f\"   Metadata: {metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Update and Delete Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Document updated\n",
      "\n",
      "Total documents after update: 5\n"
     ]
    }
   ],
   "source": [
    "# Update a document\n",
    "collection.update(\n",
    "    ids=[\"doc_0\"],\n",
    "    documents=[\"Python is an amazing programming language for AI and data science!\"],\n",
    "    metadatas=[{\"category\": \"programming\", \"topic\": \"python\", \"updated\": True}]\n",
    ")\n",
    "print(\"âœ… Document updated\")\n",
    "\n",
    "# Delete a document\n",
    "# collection.delete(ids=[\"doc_4\"])\n",
    "# print(\"âœ… Document deleted\")\n",
    "\n",
    "print(f\"\\nTotal documents after update: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Building a Complete RAG Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 RAG Retriever with Chroma\n",
    "\n",
    "Let's combine everything: chunking (Module 2), embeddings (Module 3), and vector storage (Module 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAGRetriever class defined!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class RAGRetriever:\n",
    "    def __init__(self, collection_name=\"rag_collection\", persist_dir=\"./rag_db\"):\n",
    "        \"\"\"\n",
    "        Initialize RAG retriever with Chroma.\n",
    "        \"\"\"\n",
    "        # Create Chroma client (using PersistentClient for ChromaDB 0.4.0+)\n",
    "        self.client = chromadb.PersistentClient(path=persist_dir)\n",
    "        \n",
    "        # Create collection with sentence-transformers\n",
    "        embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "            model_name=\"all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        \n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=collection_name,\n",
    "            embedding_function=embedding_fn\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… RAG Retriever initialized\")\n",
    "        print(f\"Collection: {collection_name}\")\n",
    "        print(f\"Current documents: {self.collection.count()}\")\n",
    "        print(f\"ðŸ“ Data persisted to: {persist_dir}/\")\n",
    "    \n",
    "    def chunk_text(self, text, chunk_size=500):\n",
    "        \"\"\"\n",
    "        Simple sentence-based chunking from Module 2.\n",
    "        \"\"\"\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if len(current_chunk) + len(sentence) > chunk_size and current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = sentence\n",
    "            else:\n",
    "                current_chunk += \" \" + sentence if current_chunk else sentence\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def add_document(self, text, metadata=None, source_name=\"unknown\"):\n",
    "        \"\"\"\n",
    "        Add a document (chunks it automatically).\n",
    "        \"\"\"\n",
    "        # Chunk the document\n",
    "        chunks = self.chunk_text(text)\n",
    "        \n",
    "        # Prepare data for Chroma\n",
    "        ids = [f\"{source_name}_chunk_{i}\" for i in range(len(chunks))]\n",
    "        metadatas = [\n",
    "            {\n",
    "                \"source\": source_name,\n",
    "                \"chunk_index\": i,\n",
    "                \"total_chunks\": len(chunks),\n",
    "                **(metadata or {})\n",
    "            }\n",
    "            for i in range(len(chunks))\n",
    "        ]\n",
    "        \n",
    "        # Add to collection\n",
    "        self.collection.add(\n",
    "            documents=chunks,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Added document '{source_name}': {len(chunks)} chunks\")\n",
    "        return len(chunks)\n",
    "    \n",
    "    def retrieve(self, query, top_k=3, filter_metadata=None):\n",
    "        \"\"\"\n",
    "        Retrieve relevant chunks for a query.\n",
    "        \"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=top_k,\n",
    "            where=filter_metadata\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'documents': results['documents'][0],\n",
    "            'metadatas': results['metadatas'][0],\n",
    "            'distances': results['distances'][0]\n",
    "        }\n",
    "    \n",
    "    def format_context(self, retrieved_results):\n",
    "        \"\"\"\n",
    "        Format retrieved chunks for LLM prompt.\n",
    "        \"\"\"\n",
    "        context = \"Context from retrieved documents:\\n\\n\"\n",
    "        \n",
    "        for i, (doc, metadata, distance) in enumerate(zip(\n",
    "            retrieved_results['documents'],\n",
    "            retrieved_results['metadatas'],\n",
    "            retrieved_results['distances']\n",
    "        ), 1):\n",
    "            source = metadata.get('source', 'unknown')\n",
    "            context += f\"[{i}] From {source} (Relevance: {1/(1+distance):.3f}):\\n\"\n",
    "            context += f\"{doc}\\n\\n\"\n",
    "        \n",
    "        return context\n",
    "\n",
    "print(\"âœ… RAGRetriever class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAGRetriever class defined!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# import chromadb\n",
    "# from chromadb.config import Settings\n",
    "# from chromadb import embedding_functions\n",
    "\n",
    "class RAGRetriever:\n",
    "    def __init__(self, collection_name=\"rag_collection\", persist_dir=\"./rag_db\"):\n",
    "        \"\"\"\n",
    "        Initialize RAG retriever with Chroma.\n",
    "        \"\"\"\n",
    "        # Create Chroma client with persistent storage\n",
    "        settings = Settings(\n",
    "            chroma_db_impl=\"duckdb+parquet\",\n",
    "            persist_directory=persist_dir,\n",
    "            anonymized_telemetry=False\n",
    "        )\n",
    "        self.client = chromadb.Client(settings)\n",
    "        \n",
    "        # Create collection with sentence-transformers\n",
    "        embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "            model_name=\"all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        \n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name=collection_name,\n",
    "            embedding_function=embedding_fn\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… RAG Retriever initialized\")\n",
    "        print(f\"Collection: {collection_name}\")\n",
    "        print(f\"Current documents: {self.collection.count()}\")\n",
    "        print(f\"ðŸ“ Data persisted to: {persist_dir}/\")\n",
    "    \n",
    "    def chunk_text(self, text, chunk_size=500):\n",
    "        \"\"\"\n",
    "        Simple sentence-based chunking from Module 2.\n",
    "        \"\"\"\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if len(current_chunk) + len(sentence) > chunk_size and current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "                current_chunk = sentence\n",
    "            else:\n",
    "                current_chunk += \" \" + sentence if current_chunk else sentence\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def add_document(self, text, metadata=None, source_name=\"unknown\"):\n",
    "        \"\"\"\n",
    "        Add a document (chunks it automatically).\n",
    "        \"\"\"\n",
    "        # Chunk the document\n",
    "        chunks = self.chunk_text(text)\n",
    "        \n",
    "        # Prepare data for Chroma\n",
    "        ids = [f\"{source_name}_chunk_{i}\" for i in range(len(chunks))]\n",
    "        metadatas = [\n",
    "            {\n",
    "                \"source\": source_name,\n",
    "                \"chunk_index\": i,\n",
    "                \"total_chunks\": len(chunks),\n",
    "                **(metadata or {})\n",
    "            }\n",
    "            for i in range(len(chunks))\n",
    "        ]\n",
    "        \n",
    "        # Add to collection\n",
    "        self.collection.add(\n",
    "            documents=chunks,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Added document '{source_name}': {len(chunks)} chunks\")\n",
    "        return len(chunks)\n",
    "    \n",
    "    def retrieve(self, query, top_k=3, filter_metadata=None):\n",
    "        \"\"\"\n",
    "        Retrieve relevant chunks for a query.\n",
    "        \"\"\"\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=top_k,\n",
    "            where=filter_metadata\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'documents': results['documents'][0],\n",
    "            'metadatas': results['metadatas'][0],\n",
    "            'distances': results['distances'][0]\n",
    "        }\n",
    "    \n",
    "    def format_context(self, retrieved_results):\n",
    "        \"\"\"\n",
    "        Format retrieved chunks for LLM prompt.\n",
    "        \"\"\"\n",
    "        context = \"Context from retrieved documents:\\n\\n\"\n",
    "        \n",
    "        for i, (doc, metadata, distance) in enumerate(zip(\n",
    "            retrieved_results['documents'],\n",
    "            retrieved_results['metadatas'],\n",
    "            retrieved_results['distances']\n",
    "        ), 1):\n",
    "            source = metadata.get('source', 'unknown')\n",
    "            context += f\"[{i}] From {source} (Relevance: {1/(1+distance):.3f}):\\n\"\n",
    "            context += f\"{doc}\\n\\n\"\n",
    "        \n",
    "        return context\n",
    "\n",
    "print(\"âœ… RAGRetriever class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Test the RAG Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event client_start: capture() takes 1 positional argument but 3 were given\n",
      "Using embedded DuckDB with persistence: data will be stored in: ./rag_db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG Retriever initialized\n",
      "Collection: test_rag\n",
      "Current documents: 0\n",
      "ðŸ“ Data persisted to: ./rag_db/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event collection_add: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event collection_add: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event collection_add: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Added document 'ml_intro.txt': 1 chunks\n",
      "âœ… Added document 'python_guide.txt': 1 chunks\n",
      "âœ… Added document 'vector_db_overview.txt': 1 chunks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create retriever\n",
    "retriever = RAGRetriever(collection_name=\"test_rag\")\n",
    "\n",
    "# Add sample documents\n",
    "doc1 = \"\"\"\n",
    "Machine learning is a branch of artificial intelligence that focuses on building systems \n",
    "that can learn from data. These systems improve their performance over time without being \n",
    "explicitly programmed. Common applications include image recognition, natural language \n",
    "processing, and recommendation systems.\n",
    "\"\"\"\n",
    "\n",
    "doc2 = \"\"\"\n",
    "Python is a high-level programming language known for its simplicity and readability. \n",
    "It's widely used in web development, data science, automation, and artificial intelligence. \n",
    "Python's extensive library ecosystem makes it ideal for rapid development.\n",
    "\"\"\"\n",
    "\n",
    "doc3 = \"\"\"\n",
    "Vector databases are specialized databases designed to store and query high-dimensional \n",
    "vectors efficiently. They're essential for modern AI applications like semantic search, \n",
    "recommendation systems, and retrieval-augmented generation (RAG). Popular examples include \n",
    "FAISS, Pinecone, and Chroma.\n",
    "\"\"\"\n",
    "\n",
    "# Add documents\n",
    "retriever.add_document(doc1, metadata={\"category\": \"AI\"}, source_name=\"ml_intro.txt\")\n",
    "retriever.add_document(doc2, metadata={\"category\": \"programming\"}, source_name=\"python_guide.txt\")\n",
    "retriever.add_document(doc3, metadata={\"category\": \"databases\"}, source_name=\"vector_db_overview.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are vector databases used for?\n",
      "\n",
      "================================================================================\n",
      "Context from retrieved documents:\n",
      "\n",
      "[1] From vector_db_overview.txt (Relevance: 0.781):\n",
      "Vector databases are specialized databases designed to store and query high-dimensional \n",
      "vectors efficiently. They're essential for modern AI applications like semantic search, \n",
      "recommendation systems, and retrieval-augmented generation (RAG). Popular examples include \n",
      "FAISS, Pinecone, and Chroma.\n",
      "\n",
      "[2] From ml_intro.txt (Relevance: 0.447):\n",
      "Machine learning is a branch of artificial intelligence that focuses on building systems \n",
      "that can learn from data. These systems improve their performance over time without being \n",
      "explicitly programmed. Common applications include image recognition, natural language \n",
      "processing, and recommendation systems.\n",
      "\n",
      "[3] From python_guide.txt (Relevance: 0.377):\n",
      "Python is a high-level programming language known for its simplicity and readability. It's widely used in web development, data science, automation, and artificial intelligence. Python's extensive library ecosystem makes it ideal for rapid development.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "query = \"What are vector databases used for?\"\n",
    "\n",
    "results = retriever.retrieve(query, top_k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\"*80)\n",
    "print(retriever.format_context(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 6. Advanced Retrieval Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Reranking\n",
    "\n",
    "Retrieve more candidates (e.g., top 20), then rerank them using a more sophisticated model to get the final top k.\n",
    "\n",
    "**Benefits:**\n",
    "- Better quality than single-stage retrieval\n",
    "- Can use cross-encoder models (more accurate but slower)\n",
    "\n",
    "**How it works:**\n",
    "1. Retrieval: Get top 20 candidates (fast, approximate)\n",
    "2. Reranking: Score all 20 with better model\n",
    "3. Return: Top 3 after reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Hybrid Search\n",
    "\n",
    "Combine semantic search (embeddings) with keyword search (BM25, TF-IDF).\n",
    "\n",
    "**Why hybrid?**\n",
    "- Semantic search: Good for concepts and meaning\n",
    "- Keyword search: Good for exact terms and names\n",
    "- Together: Best of both worlds\n",
    "\n",
    "**Implementation:**\n",
    "1. Get results from semantic search\n",
    "2. Get results from keyword search\n",
    "3. Combine and rerank (e.g., weighted average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 MMR (Maximal Marginal Relevance)\n",
    "\n",
    "Retrieve diverse results instead of very similar ones.\n",
    "\n",
    "**Problem:** Top 3 results might be too similar (redundant)\n",
    "\n",
    "**Solution:** MMR balances relevance and diversity\n",
    "- Pick most relevant document first\n",
    "- For next picks, balance relevance to query vs. difference from already selected docs\n",
    "\n",
    "**Use when:** You want variety in retrieved context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. Performance Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Index Selection\n",
    "\n",
    "Choose the right FAISS index based on your needs:\n",
    "\n",
    "**For accuracy (small datasets < 10k vectors):**\n",
    "- `IndexFlatL2` or `IndexFlatIP`: Exact search, no approximation\n",
    "\n",
    "**For speed (medium datasets 10k-1M vectors):**\n",
    "- `IndexIVFFlat`: Clusters data, searches subset\n",
    "- `IndexHNSWFlat`: Graph-based, very fast\n",
    "\n",
    "**For memory (large datasets > 1M vectors):**\n",
    "- `IndexIVFPQ`: Compressed vectors, saves memory\n",
    "- Trade-off: Faster and smaller, but less accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Batch Processing\n",
    "\n",
    "Add documents in batches instead of one by one for better performance.\n",
    "\n",
    "```python\n",
    "# Slow: Adding one at a time\n",
    "for doc in documents:\n",
    "    collection.add(documents=[doc], ids=[...])\n",
    "\n",
    "# Fast: Adding in batch\n",
    "collection.add(documents=documents, ids=[...])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Dimension Reduction\n",
    "\n",
    "Reduce embedding dimensions to save memory and improve speed.\n",
    "\n",
    "**Example:** 768 dims â†’ 384 dims or 256 dims\n",
    "\n",
    "**Trade-off:** Faster and smaller, slightly lower quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Practice Exercises\n",
    "\n",
    "## Exercise 1: Chroma with Advanced Filtering\n",
    "\n",
    "### Task\n",
    "Build a document management system using Chroma with rich metadata and filtering.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Create a collection of at least 30 documents with metadata:\n",
    "   ```python\n",
    "   metadata = {\n",
    "       \"category\": \"...\",  # e.g., \"tech\", \"business\", \"science\"\n",
    "       \"date\": \"...\",      # e.g., \"2024-01-15\"\n",
    "       \"author\": \"...\",    # e.g., \"John Doe\"\n",
    "       \"priority\": ...    # e.g., 1, 2, 3\n",
    "   }\n",
    "   ```\n",
    "\n",
    "2. Implement queries with different filters:\n",
    "   - By category\n",
    "   - By date range\n",
    "   - By author\n",
    "   - Combined filters (e.g., category AND date)\n",
    "\n",
    "3. Test MMR (Maximal Marginal Relevance) if Chroma supports it\n",
    "\n",
    "4. Compare results with and without filters\n",
    "\n",
    "### Sample Data\n",
    "\n",
    "```python\n",
    "documents = [\n",
    "    {\n",
    "        \"text\": \"Python 3.12 introduces new performance improvements...\",\n",
    "        \"metadata\": {\n",
    "            \"category\": \"tech\",\n",
    "            \"date\": \"2024-01-15\",\n",
    "            \"author\": \"Tech Team\",\n",
    "            \"priority\": 1\n",
    "        }\n",
    "    },\n",
    "    # Add 29 more...\n",
    "]\n",
    "```\n",
    "\n",
    "### Expected Output\n",
    "\n",
    "```\n",
    "Query: \"latest technology updates\"\n",
    "\n",
    "Without filters:\n",
    "1. [Result from any category]\n",
    "2. [Result from any category]\n",
    "3. [Result from any category]\n",
    "\n",
    "With filter (category=\"tech\"):\n",
    "1. [Tech result]\n",
    "2. [Tech result]\n",
    "3. [Tech result]\n",
    "\n",
    "With filter (category=\"tech\" AND date>=\"2024-01-01\"):\n",
    "1. [Recent tech result]\n",
    "2. [Recent tech result]\n",
    "3. [Recent tech result]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 8. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Vector databases enable fast similarity search** at scale using approximate nearest neighbor algorithms.\n",
    "\n",
    "2. **FAISS** is great for learning, prototyping, and maximum flexibility. Requires manual persistence.\n",
    "\n",
    "3. **Chroma** is perfect for RAG applications with automatic persistence, metadata support, and simple API.\n",
    "\n",
    "4. **Production systems** typically use managed services like Pinecone or self-hosted solutions like Weaviate/Qdrant.\n",
    "\n",
    "5. **Metadata filtering** allows you to narrow search to specific document types or categories.\n",
    "\n",
    "6. **Advanced techniques** like reranking, hybrid search, and MMR improve retrieval quality.\n",
    "\n",
    "7. **Choose the right index** based on your dataset size and accuracy requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "In **Module 5: Building Your First Complete RAG System**, you'll:\n",
    "- Combine all modules into a working RAG application\n",
    "- Add an LLM for generation\n",
    "- Handle document uploads\n",
    "- Create a simple interface\n",
    "- Test with real queries\n",
    "\n",
    "Get ready to build a complete system! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
