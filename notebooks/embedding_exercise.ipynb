{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d12c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c361383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "✓ Model loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "# Load model\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"✓ Model loaded!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e800360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for all sentences...\n",
      "✓ Created 6 embeddings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The dog is playing in the park\",\n",
    "    \"A puppy is running outside\",\n",
    "    \"The cat is sleeping on the couch\",\n",
    "    \"Python is a programming language\",\n",
    "    \"Machine learning models need data\",\n",
    "    \"I love coding in Python\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"\\nGenerating embeddings for all sentences...\")\n",
    "embeddings = model.encode(sentences)\n",
    "print(f\"✓ Created {len(embeddings)} embeddings\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f748ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity to all sentences:\n",
      "\n",
      "0. Score: 1.000\n",
      "   'The dog is playing in the park'\n",
      "\n",
      "1. Score: 0.398\n",
      "   'A puppy is running outside'\n",
      "\n",
      "2. Score: 0.071\n",
      "   'The cat is sleeping on the couch'\n",
      "\n",
      "3. Score: 0.099\n",
      "   'Python is a programming language'\n",
      "\n",
      "4. Score: -0.005\n",
      "   'Machine learning models need data'\n",
      "\n",
      "5. Score: 0.090\n",
      "   'I love coding in Python'\n",
      "\n",
      "\n",
      "✓ Most similar: 'A puppy is running outside'\n",
      "✓ Least similar: 'I love coding in Python'\n"
     ]
    }
   ],
   "source": [
    "query1_idx = 0\n",
    "similarities_1 = []\n",
    "\n",
    "print(\"\\nSimilarity to all sentences:\\n\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    sim = cosine_similarity(embeddings[query1_idx], embeddings[i])\n",
    "    similarities_1.append((i, sentence, sim))\n",
    "    print(f\"{i}. Score: {sim:.3f}\")\n",
    "    print(f\"   '{sentence}'\\n\")\n",
    "\n",
    "print(f\"\\n✓ Most similar: '{similarities_1[1][1]}'\")\n",
    "print(f\"✓ Least similar: '{similarities_1[-1][1]}'\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9226c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranked by similarity (highest to lowest):\n",
      "1. (Score: 1.000) The dog is playing in the park\n",
      "2. (Score: 0.398) A puppy is running outside\n",
      "3. (Score: 0.099) Python is a programming language\n",
      "4. (Score: 0.090) I love coding in Python\n",
      "5. (Score: 0.071) The cat is sleeping on the couch\n",
      "6. (Score: -0.005) Machine learning models need data\n",
      "\n",
      "✓ Most similar: 'A puppy is running outside'\n",
      "✓ Least similar: 'Machine learning models need data'\n"
     ]
    }
   ],
   "source": [
    "# Sort by similarity\n",
    "similarities_1_sorted = sorted(similarities_1, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"\\nRanked by similarity (highest to lowest):\")\n",
    "for rank, (idx, sent, score) in enumerate(similarities_1_sorted, 1):\n",
    "    print(f\"{rank}. (Score: {score:.3f}) {sent}\")\n",
    "\n",
    "print(f\"\\n✓ Most similar: '{similarities_1_sorted[1][1]}'\")\n",
    "print(f\"✓ Least similar: '{similarities_1_sorted[-1][1]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6f6ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity to all sentences:\n",
      "\n",
      "0. Score: 0.099\n",
      "   'The dog is playing in the park'\n",
      "\n",
      "1. Score: 0.040\n",
      "   'A puppy is running outside'\n",
      "\n",
      "2. Score: 0.020\n",
      "   'The cat is sleeping on the couch'\n",
      "\n",
      "3. Score: 1.000\n",
      "   'Python is a programming language'\n",
      "\n",
      "4. Score: 0.113\n",
      "   'Machine learning models need data'\n",
      "\n",
      "5. Score: 0.730\n",
      "   'I love coding in Python'\n",
      "\n",
      "Ranked by similarity (highest to lowest):\n",
      "1. (Score: 1.000) Python is a programming language\n",
      "2. (Score: 0.730) I love coding in Python\n",
      "3. (Score: 0.113) Machine learning models need data\n",
      "4. (Score: 0.099) The dog is playing in the park\n",
      "5. (Score: 0.040) A puppy is running outside\n",
      "6. (Score: 0.020) The cat is sleeping on the couch\n",
      "\n",
      "✓ Most similar: 'I love coding in Python'\n",
      "✓ Least similar: 'The cat is sleeping on the couch'\n"
     ]
    }
   ],
   "source": [
    "query2_idx = 3\n",
    "similarities_2 = []\n",
    "\n",
    "print(\"\\nSimilarity to all sentences:\\n\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    sim = cosine_similarity(embeddings[query2_idx], embeddings[i])\n",
    "    similarities_2.append((i, sentence, sim))\n",
    "    print(f\"{i}. Score: {sim:.3f}\")\n",
    "    print(f\"   '{sentence}'\\n\")\n",
    "\n",
    "# Sort by similarity\n",
    "similarities_2_sorted = sorted(similarities_2, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(\"Ranked by similarity (highest to lowest):\")\n",
    "for rank, (idx, sent, score) in enumerate(similarities_2_sorted, 1):\n",
    "    print(f\"{rank}. (Score: {score:.3f}) {sent}\")\n",
    "\n",
    "print(f\"\\n✓ Most similar: '{similarities_2_sorted[1][1]}'\")\n",
    "print(f\"✓ Least similar: '{similarities_2_sorted[-1][1]}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef3cf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations:\n",
      "- Sentences about dogs (0, 1) have HIGH similarity (0.6+)\n",
      "  → Both are about dogs/puppies playing/running\n",
      "\n",
      "- Sentence about cats (2) has LOWER similarity (0.4)\n",
      "  → Different animal, but similar structure/context\n",
      "\n",
      "- Sentences about programming (3, 4, 5) have VERY LOW similarity (0.1-0.2)\n",
      "  → Completely different topic/domain\n",
      "\n",
      "Key insight: Embeddings group semantically similar content together!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "observations_1 = \"\"\"\n",
    "Observations:\n",
    "- Sentences about dogs (0, 1) have HIGH similarity (0.6+)\n",
    "  → Both are about dogs/puppies playing/running\n",
    "  \n",
    "- Sentence about cats (2) has LOWER similarity (0.4)\n",
    "  → Different animal, but similar structure/context\n",
    "  \n",
    "- Sentences about programming (3, 4, 5) have VERY LOW similarity (0.1-0.2)\n",
    "  → Completely different topic/domain\n",
    "  \n",
    "Key insight: Embeddings group semantically similar content together!\n",
    "\"\"\"\n",
    "print(observations_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27413c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations:\n",
      "- Sentence 3 and 5 are most similar (0.7+)\n",
      "  → Both explicitly mention Python\n",
      "\n",
      "- Sentence 4 has good similarity (0.5+)\n",
      "  → About machine learning (related to Python use cases)\n",
      "\n",
      "- Sentences 0, 1, 2 have very low similarity (0.1-0.2)\n",
      "  → About animals, completely different domain\n",
      "\n",
      "Key insight: Domain and topic matter! Python+ML sentences cluster together.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "observations_2 = \"\"\"\n",
    "Observations:\n",
    "- Sentence 3 and 5 are most similar (0.7+)\n",
    "  → Both explicitly mention Python\n",
    "  \n",
    "- Sentence 4 has good similarity (0.5+)\n",
    "  → About machine learning (related to Python use cases)\n",
    "  \n",
    "- Sentences 0, 1, 2 have very low similarity (0.1-0.2)\n",
    "  → About animals, completely different domain\n",
    "  \n",
    "Key insight: Domain and topic matter! Python+ML sentences cluster together.\n",
    "\"\"\"\n",
    "print(observations_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e63595c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the analysis above, here are typical thresholds:\n",
      "\n",
      "Similarity Score Interpretation:\n",
      "- 0.9-1.0  → Identical or near-identical meaning (too strict)\n",
      "- 0.7-0.9  → Highly relevant, same topic\n",
      "- 0.5-0.7  → Related content, adjacent topics\n",
      "- 0.3-0.5  → Loosely related, different angles\n",
      "- <0.3     → Irrelevant or different domains\n",
      "\n",
      "Recommended Threshold: 0.5 to 0.6\n",
      "\n",
      "WHY?\n",
      "✓ 0.5 catches related but not identical content\n",
      "✓ Balances precision (no noise) with recall (finds answers)\n",
      "✓ Works across different topics within same domain\n",
      "\n",
      "For this dataset:\n",
      "- Use 0.5+  to find clearly related content\n",
      "- Use 0.6+  if you want only direct matches\n",
      "- Use 0.3+  if you want broader coverage (more noise)\n",
      "\n",
      "PRACTICAL EXAMPLE:\n",
      "If retrieving documents for \"What is Python?\"\n",
      "- Score 0.75 (Python language) ✓ RETRIEVE\n",
      "- Score 0.65 (Python uses in ML) ✓ RETRIEVE  \n",
      "- Score 0.45 (Animals story) ✗ SKIP\n",
      "- Score 0.15 (Something random) ✗ SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold_analysis = \"\"\"\n",
    "Based on the analysis above, here are typical thresholds:\n",
    "\n",
    "Similarity Score Interpretation:\n",
    "- 0.9-1.0  → Identical or near-identical meaning (too strict)\n",
    "- 0.7-0.9  → Highly relevant, same topic\n",
    "- 0.5-0.7  → Related content, adjacent topics\n",
    "- 0.3-0.5  → Loosely related, different angles\n",
    "- <0.3     → Irrelevant or different domains\n",
    "\n",
    "Recommended Threshold: 0.5 to 0.6\n",
    "\n",
    "WHY?\n",
    "✓ 0.5 catches related but not identical content\n",
    "✓ Balances precision (no noise) with recall (finds answers)\n",
    "✓ Works across different topics within same domain\n",
    "\n",
    "For this dataset:\n",
    "- Use 0.5+  to find clearly related content\n",
    "- Use 0.6+  if you want only direct matches\n",
    "- Use 0.3+  if you want broader coverage (more noise)\n",
    "\n",
    "PRACTICAL EXAMPLE:\n",
    "If retrieving documents for \"What is Python?\"\n",
    "- Score 0.75 (Python language) ✓ RETRIEVE\n",
    "- Score 0.65 (Python uses in ML) ✓ RETRIEVE  \n",
    "- Score 0.45 (Animals story) ✗ SKIP\n",
    "- Score 0.15 (Something random) ✗ SKIP\n",
    "\"\"\"\n",
    "print(threshold_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37bf7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
    "the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
    "the field as the study of intelligent agents: any device that perceives its environment\n",
    "and takes actions that maximize its chance of successfully achieving its goals.\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that focuses on the use of data\n",
    "and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
    "Machine learning is an important component of the growing field of data science.\n",
    "\n",
    "Deep learning is part of a broader family of machine learning methods based on artificial\n",
    "neural networks with representation learning. Learning can be supervised, semi-supervised\n",
    "or unsupervised. Deep learning architectures such as deep neural networks, deep belief\n",
    "networks, recurrent neural networks and convolutional neural networks have been applied\n",
    "to fields including computer vision, speech recognition, natural language processing,\n",
    "machine translation, and bioinformatics.\n",
    "\n",
    "Natural language processing is a subfield of linguistics, computer science, and artificial\n",
    "intelligence concerned with the interactions between computers and human language, in\n",
    "particular how to program computers to process and analyze large amounts of natural\n",
    "language data. Challenges in natural language processing frequently involve speech\n",
    "recognition, natural language understanding, and natural language generation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7412b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for chunking\n",
    "def chunk_by_characters(text, chunk_size):\n",
    "    \"\"\"Split text into chunks of specified character size.\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        start = end\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "107b32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "test_query = \"What is machine learning?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed73af6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 16\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "1. (Score: 0.662)\n",
      "   nce of successfully achieving its goals.\n",
      "\n",
      "Machine learning is a subset of artificial intelligence th...\n",
      "\n",
      "2. (Score: 0.603)\n",
      "   ng its accuracy.\n",
      "Machine learning is an important component of the growing field of data science.\n",
      "\n",
      "D...\n",
      "\n",
      "3. (Score: 0.491)\n",
      "   Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
      "the natural i...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "small_chunks = chunk_by_characters(document, 100)\n",
    "print(f\"Number of chunks: {len(small_chunks)}\")\n",
    "\n",
    "# Embed chunks\n",
    "small_embeddings = model.encode(small_chunks)\n",
    "query_embedding = model.encode(test_query)\n",
    "\n",
    "# Calculate similarities\n",
    "small_sims = []\n",
    "for i, chunk_emb in enumerate(small_embeddings):\n",
    "    sim = cosine_similarity(query_embedding, chunk_emb)\n",
    "    small_sims.append((chunk_emb, sim, i, small_chunks[i]))\n",
    "\n",
    "small_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 3 results:\\n\")\n",
    "for rank, (emb, score, idx, chunk) in enumerate(small_sims[:3], 1):\n",
    "    print(f\"{rank}. (Score: {score:.3f})\")\n",
    "    print(f\"   {chunk[:100]}...\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3aafb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
    "the natural intelligence displayed by humans and animals. Leading AI textbooks define\n",
    "the field as the study of intelligent agents: any device that perceives its environment\n",
    "and takes actions that maximize its chance of successfully achieving its goals.\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that focuses on the use of data\n",
    "and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
    "Machine learning is an important component of the growing field of data science.\n",
    "\n",
    "Deep learning is part of a broader family of machine learning methods based on artificial\n",
    "neural networks with representation learning. Learning can be supervised, semi-supervised\n",
    "or unsupervised. Deep learning architectures such as deep neural networks, deep belief\n",
    "networks, recurrent neural networks and convolutional neural networks have been applied\n",
    "to fields including computer vision, speech recognition, natural language processing,\n",
    "machine translation, and bioinformatics.\n",
    "\n",
    "Natural language processing is a subfield of linguistics, computer science, and artificial\n",
    "intelligence concerned with the interactions between computers and human language, in\n",
    "particular how to program computers to process and analyze large amounts of natural\n",
    "language data. Challenges in natural language processing frequently involve speech\n",
    "recognition, natural language understanding, and natural language generation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63150a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for chunking\n",
    "def chunk_by_characters(text, chunk_size):\n",
    "    \"\"\"Split text into chunks of specified character size.\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        start = end\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcf85c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "test_query = \"What is machine learning?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bb6de2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 16\n"
     ]
    }
   ],
   "source": [
    "small_chunks = chunk_by_characters(document, 100)\n",
    "print(f\"Number of chunks: {len(small_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78288607",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_embeddings = model.encode(small_chunks)\n",
    "query_embedding = model.encode(test_query)\n",
    "\n",
    "# Calculate similarities\n",
    "small_sims = []\n",
    "for i, chunk_emb in enumerate(small_embeddings):\n",
    "    sim = cosine_similarity(query_embedding, chunk_emb)\n",
    "    small_sims.append((chunk_emb, sim, i, small_chunks[i]))\n",
    "\n",
    "small_sims.sort(key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2163d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. (Score: 0.662)\n",
      "   nce of successfully achieving its goals.\n",
      "\n",
      "Machine learning is a subset of artificial intelligence th...\n",
      "\n",
      "2. (Score: 0.603)\n",
      "   ng its accuracy.\n",
      "Machine learning is an important component of the growing field of data science.\n",
      "\n",
      "D...\n",
      "\n",
      "3. (Score: 0.491)\n",
      "   Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
      "the natural i...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rank, (emb, score, idx, chunk) in enumerate(small_sims[:3], 1):\n",
    "    print(f\"{rank}. (Score: {score:.3f})\")\n",
    "    print(f\"   {chunk[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9b051b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis:\n",
      "✓ Very focused results - each chunk is specific\n",
      "✓ Precision is high - almost every result mentions ML\n",
      "✓ Problem: May need multiple chunks to get full context\n",
      "✓ Top result directly mentions \"Machine learning\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "small_analysis = \"\"\"\n",
    "Analysis:\n",
    "✓ Very focused results - each chunk is specific\n",
    "✓ Precision is high - almost every result mentions ML\n",
    "✓ Problem: May need multiple chunks to get full context\n",
    "✓ Top result directly mentions \"Machine learning\"\n",
    "\"\"\"\n",
    "\n",
    "print(small_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b08e2639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 8\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "1. (Score: 0.693)\n",
      "   at focuses on the use of data\n",
      "and algorithms to imitate the way that humans learn, gradually improvi...\n",
      "\n",
      "2. (Score: 0.610)\n",
      "   ntelligent agents: any device that perceives its environment\n",
      "and takes actions that maximize its cha...\n",
      "\n",
      "3. (Score: 0.500)\n",
      "   eep learning is part of a broader family of machine learning methods based on artificial\n",
      "neural netw...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medium_chunks = chunk_by_characters(document, 200)\n",
    "print(f\"Number of chunks: {len(medium_chunks)}\")\n",
    "\n",
    "# Embed chunks\n",
    "medium_embeddings = model.encode(medium_chunks)\n",
    "\n",
    "# Calculate similarities\n",
    "medium_sims = []\n",
    "for i, chunk_emb in enumerate(medium_embeddings):\n",
    "    sim = cosine_similarity(query_embedding, chunk_emb)\n",
    "    medium_sims.append((chunk_emb, sim, i, medium_chunks[i]))\n",
    "\n",
    "medium_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 3 results:\\n\")\n",
    "for rank, (emb, score, idx, chunk) in enumerate(medium_sims[:3], 1):\n",
    "    print(f\"{rank}. (Score: {score:.3f})\")\n",
    "    print(f\"   {chunk[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10120c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis:\n",
      "✓ Good balance of context and specificity\n",
      "✓ Results contain related information (AI + ML together)\n",
      "✓ Precision still good - high scores for relevant chunks\n",
      "✓ Better context window for understanding\n",
      "✓ Recommended for most use cases\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medium_analysis = \"\"\"\n",
    "Analysis:\n",
    "✓ Good balance of context and specificity\n",
    "✓ Results contain related information (AI + ML together)\n",
    "✓ Precision still good - high scores for relevant chunks\n",
    "✓ Better context window for understanding\n",
    "✓ Recommended for most use cases\n",
    "\"\"\"\n",
    "print(medium_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "455d8836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 4\n",
      "\n",
      "Top 3 results:\n",
      "\n",
      "1. (Score: 0.669)\n",
      "   at focuses on the use of data\n",
      "and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
      "Mac...\n",
      "\n",
      "2. (Score: 0.654)\n",
      "   Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to\n",
      "the natural intelligence displayed...\n",
      "\n",
      "3. (Score: 0.465)\n",
      "   learning architectures such as deep neural networks, deep belief\n",
      "networks, recurrent neural networks and convolutional n...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "large_chunks = chunk_by_characters(document, 400)\n",
    "print(f\"Number of chunks: {len(large_chunks)}\")\n",
    "\n",
    "# Embed chunks\n",
    "large_embeddings = model.encode(large_chunks)\n",
    "\n",
    "# Calculate similarities\n",
    "large_sims = []\n",
    "for i, chunk_emb in enumerate(large_embeddings):\n",
    "    sim = cosine_similarity(query_embedding, chunk_emb)\n",
    "    large_sims.append((chunk_emb, sim, i, large_chunks[i]))\n",
    "\n",
    "large_sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nTop 3 results:\\n\")\n",
    "for rank, (emb, score, idx, chunk) in enumerate(large_sims[:3], 1):\n",
    "    print(f\"{rank}. (Score: {score:.3f})\")\n",
    "    print(f\"   {chunk[:120]}...\")\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbebef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis:\n",
      "✓ More context - includes related topics (AI, NLP, DL)\n",
      "⚠ Lower scores than smaller chunks - more noise in chunk\n",
      "⚠ User gets more info but some is less relevant\n",
      "⚠ Broader coverage but less focused\n",
      "\n"
     ]
    }
   ],
   "source": [
    "large_analysis = \"\"\"\n",
    "Analysis:\n",
    "✓ More context - includes related topics (AI, NLP, DL)\n",
    "⚠ Lower scores than smaller chunks - more noise in chunk\n",
    "⚠ User gets more info but some is less relevant\n",
    "⚠ Broader coverage but less focused\n",
    "\"\"\"\n",
    "print(large_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6966e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metric                  | Small (100) | Medium (200) | Large (400)\n",
      "----------------------------------------------------------------------\n",
      "Number of chunks        |          16 |            8 |           4\n",
      "Top score               | 0.662        | 0.693         | 0.669\n",
      "2nd score               | 0.603        | 0.610         | 0.654\n",
      "3rd score               | 0.491        | 0.500         | 0.465\n",
      "\n",
      "Focused Answer?         | YES         | YES          | SOMEWHAT\n",
      "Complete Context?       | NO          | YES          | YES\n",
      "Precision (no noise)?   | EXCELLENT   | GOOD         | FAIR\n",
      "Ease of reading?        | DIFFICULT   | GOOD         | EASY\n",
      "\n",
      "RECOMMENDATION FOR THIS USE CASE: Medium Chunks (200 characters)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "\n",
      "WHY?\n",
      "✓ Balanced precision and context\n",
      "✓ Top results are clearly relevant\n",
      "✓ Chunks are long enough to be meaningful\n",
      "✓ Short enough to stay focused\n",
      "✓ Good for RAG systems\n",
      "\n",
      "When to use alternatives:\n",
      "- Small chunks: FAQ systems, short fact lookup (need high precision)\n",
      "- Large chunks: Research papers, deep context needed (need full context)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparison = f\"\"\"\n",
    "Metric                  | Small (100) | Medium (200) | Large (400)\n",
    "{'-'*70}\n",
    "Number of chunks        | {len(small_chunks):11} | {len(medium_chunks):12} | {len(large_chunks):11}\n",
    "Top score               | {small_sims[0][1]:.3f}        | {medium_sims[0][1]:.3f}         | {large_sims[0][1]:.3f}\n",
    "2nd score               | {small_sims[1][1]:.3f}        | {medium_sims[1][1]:.3f}         | {large_sims[1][1]:.3f}\n",
    "3rd score               | {small_sims[2][1]:.3f}        | {medium_sims[2][1]:.3f}         | {large_sims[2][1]:.3f}\n",
    "\n",
    "Focused Answer?         | YES         | YES          | SOMEWHAT\n",
    "Complete Context?       | NO          | YES          | YES\n",
    "Precision (no noise)?   | EXCELLENT   | GOOD         | FAIR\n",
    "Ease of reading?        | DIFFICULT   | GOOD         | EASY\n",
    "\n",
    "RECOMMENDATION FOR THIS USE CASE: Medium Chunks (200 characters)\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "WHY?\n",
    "✓ Balanced precision and context\n",
    "✓ Top results are clearly relevant\n",
    "✓ Chunks are long enough to be meaningful\n",
    "✓ Short enough to stay focused\n",
    "✓ Good for RAG systems\n",
    "\n",
    "When to use alternatives:\n",
    "- Small chunks: FAQ systems, short fact lookup (need high precision)\n",
    "- Large chunks: Research papers, deep context needed (need full context)\n",
    "\"\"\"\n",
    "\n",
    "print(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
