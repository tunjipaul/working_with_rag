{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Patterns: ReAct, Plan-Execute, and Reflection\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand core agentic design patterns\n",
    "- Build ReAct pattern from scratch\n",
    "- Use helper functions for quick agent creation\n",
    "- Implement Plan-Execute and Reflection patterns\n",
    "- Know when to use manual graphs vs helpers\n",
    "\n",
    "**Prerequisites:** Notebooks 01, 02, 03 (LangGraph Basics, Tools, Agentic RAG)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introduction to Agentic Patterns\n",
    "\n",
    "In notebooks 01-03, you built agents from scratch using StateGraph. But there are **common patterns** that appear repeatedly in agent design.\n",
    "\n",
    "### What Are Agentic Patterns?\n",
    "\n",
    "Agentic patterns are reusable blueprints for building agents.\n",
    "**Instead of asking:** â€œHow do I design this agent from scratch?â€\n",
    "**You ask:** â€œWhich pattern fits this problem best?â€\n",
    "\n",
    "Think of patterns like design templates for reasoning + tool usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Three Core Agentic Patterns\n",
    "\n",
    "**ReAct** (Reason + Act)\n",
    "- Think â†’ Act â†’ Observe â†’ Repeat\n",
    "- Most common pattern for tool-using agents\n",
    "- What you've been building in previous notebooks\n",
    "\n",
    "**Plan-Execute**\n",
    "- Plan all steps upfront â†’ Execute each step\n",
    "- Better for complex multi-step tasks\n",
    "- Can replan if execution fails\n",
    "\n",
    "**Reflection**\n",
    "- Generate â†’ Self-critique â†’ Refine â†’ Return\n",
    "- Best for quality-critical outputs\n",
    "- Similar to Self-RAG but more general\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Learn Patterns?\n",
    "\n",
    "1. **Faster development** - Don't reinvent the wheel\n",
    "2. **Better designs** - Learn from proven approaches\n",
    "3. **Common language** - Communicate with other developers\n",
    "4. **Production ready** - Used in real systems\n",
    "\n",
    "**Today you'll master all three patterns!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langgraph langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode, create_react_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal, TypedDict, Annotated\n",
    "import operator\n",
    "import os\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found!\")\n",
    "\n",
    "print(\"âœ… API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"âœ… LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: ReAct Pattern - The Foundation\n",
    "\n",
    "### What is ReAct?\n",
    "\n",
    "**ReAct = Reasoning + Acting**\n",
    "\n",
    "The agent alternates between thinking and acting:\n",
    "\n",
    "```\n",
    "User Query\n",
    "   â†“\n",
    "1. REASON: \"I need to calculate this\"\n",
    "   â†“\n",
    "2. ACT: Call calculator tool\n",
    "   â†“\n",
    "3. OBSERVE: Look at the tool result\n",
    "   â†“\n",
    "4. REASON: \"Now I have the answer\"\n",
    "   â†“\n",
    "5. RESPOND: Return final answer\n",
    "```\n",
    "\n",
    "This is what you've been building in Notebooks 02-03!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate mathematical expressions.\n",
    "    \n",
    "    Args:\n",
    "        expression: Math expression like \"2 + 2\" or \"15 * 37\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information (simulated).\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "    \"\"\"\n",
    "    # Simulated search results\n",
    "    knowledge = {\n",
    "        \"python\": \"Python is a high-level programming language created in 1991.\",\n",
    "        \"langgraph\": \"LangGraph is a framework for building stateful multi-actor applications.\",\n",
    "        \"react\": \"ReAct is an agent pattern that combines reasoning and acting.\"\n",
    "    }\n",
    "    \n",
    "    for key, value in knowledge.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "    \n",
    "    return \"No information found.\"\n",
    "\n",
    "tools = [calculator, search]\n",
    "print(\"âœ… Tools created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: ReAct - Manual Implementation\n",
    "\n",
    "First, let's build ReAct **from scratch** to understand how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# System prompt\n",
    "react_prompt = SystemMessage(content=\"\"\"You are a helpful assistant with tools.\n",
    "\n",
    "Use calculator for math and search for information.\n",
    "Think step-by-step before using tools.\"\"\")\n",
    "\n",
    "# Define nodes\n",
    "def react_assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"Agent node - reasons and decides which tool to use.\"\"\"\n",
    "    messages = [react_prompt] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"Route to tools or end.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "# Build graph\n",
    "react_builder = StateGraph(MessagesState)\n",
    "react_builder.add_node(\"assistant\", react_assistant)\n",
    "react_builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "react_builder.add_edge(START, \"assistant\")\n",
    "react_builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "react_builder.add_edge(\"tools\", \"assistant\")  # Loop back for multi-step reasoning\n",
    "\n",
    "react_agent_manual = react_builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "print(\"âœ… ReAct agent (manual) created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "try:\n",
    "    display(Image(react_agent_manual.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph: START â†’ assistant â†” tools â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸŽ¨ Notice the cycle:** assistant â†” tools allows multi-step reasoning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Manual ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(agent, query: str, agent_name: str = \"Agent\"):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ðŸ‘¤ User: {query}\")\n",
    "    print(f\"ðŸ¤– {agent_name} (FULL TRACE)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=query)]},\n",
    "        config={\"configurable\": {\"thread_id\": f\"test_{agent_name}\"}}\n",
    "    )\n",
    "\n",
    "    for i, msg in enumerate(result[\"messages\"]):\n",
    "        print(f\"\\n--- Step {i+1} ---\")\n",
    "\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            print(\"ðŸ‘¤ Human:\")\n",
    "            print(msg.content)\n",
    "\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            print(\"ðŸ¤– Assistant:\")\n",
    "            print(msg.content)\n",
    "\n",
    "            # ðŸ”¥ THIS IS IMPORTANT\n",
    "            if msg.tool_calls:\n",
    "                print(\"\\nðŸ›  Tool Calls:\")\n",
    "                for tc in msg.tool_calls:\n",
    "                    print(f\"  â€¢ Tool name: {tc['name']}\")\n",
    "                    print(f\"  â€¢ Arguments: {tc['args']}\")\n",
    "\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            print(\"ðŸ§° Tool Result:\")\n",
    "            print(f\"Tool: {msg.name}\")\n",
    "            print(f\"Output: {msg.content}\")\n",
    "\n",
    "    final_answer = result[\"messages\"][-1].content\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"âœ… FINAL ANSWER:\")\n",
    "    print(final_answer)\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-step test\n",
    "test_agent(\n",
    "    react_agent_manual,\n",
    "    \"What is react ?\",\n",
    "    \"Manual ReAct_0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-step test\n",
    "test_agent(\n",
    "    react_agent_manual,\n",
    "    \"Search for information about Python, then calculate 2 ** 10\",\n",
    "    \"Manual ReAct_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸŽ¯ Observe:** Agent uses MULTIPLE tools in sequence - this is ReAct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-step test\n",
    "test_agent(\n",
    "    react_agent_manual,\n",
    "    \"What is LLM\",\n",
    "    \"Manual ReAct_33\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸŽ¯ Observe:** Seach couldn't find any information, the agent has to respond through the llm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: ReAct - Using Helper Functions\n",
    "\n",
    "Now let's see the **shortcut** way using LangGraph's helper function.\n",
    "\n",
    "### Why Helpers Exist\n",
    "\n",
    "Building graphs manually is great for learning, but:\n",
    "- **Repetitive** for common patterns\n",
    "- **Time-consuming** for simple agents\n",
    "- **Error-prone** if you forget edges\n",
    "\n",
    "Helpers create the graph structure for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using create_react_agent helper\n",
    "react_agent_helper = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    prompt=react_prompt\n",
    ")\n",
    "\n",
    "print(\"âœ… ReAct agent (helper) created\")\n",
    "print(\"\\nâš ï¸ Note: create_react_agent may show deprecation warning.\")\n",
    "print(\"   This is OK - it's being moved to langchain.agents but still works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ’¡ That's it!** One function call replaces all our manual graph building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Helper ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agent(react_agent_helper, \"What is 123 * 456?\", \"Helper ReAct_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "create_agent_helper = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=react_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agent(create_agent_helper, \"What is 123 * 456?\", \"Helper ReAct_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same multi-step test\n",
    "test_agent(\n",
    "    react_agent_helper,\n",
    "    \"Search for information about LangGraph, then calculate 15 * 25\",\n",
    "    \"Helper ReAct_0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸŽ‰ Same behavior!** The helper creates the same graph structure internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Manual vs Helper - When to Use Which?\n",
    "\n",
    "### Code Comparison\n",
    "\n",
    "**Manual (20+ lines):**\n",
    "```python\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "def assistant(state): ...\n",
    "def should_continue(state): ...\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(...)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "agent = builder.compile()\n",
    "```\n",
    "\n",
    "**Helper (3 lines):**\n",
    "```python\n",
    "agent = create_react_agent(\n",
    "    model=llm, tools=tools, prompt=prompt\n",
    ")\n",
    "```\n",
    "\n",
    "### Feature Comparison\n",
    "\n",
    "| Feature | Manual Building | Helper Function |\n",
    "|---------|----------------|----------------|\n",
    "| **Lines of code** | 20-30 | 3-5 |\n",
    "| **Learning value** | âœ… High | âš ï¸ Low (black box) |\n",
    "| **Flexibility** | âœ… Full control | âŒ Limited |\n",
    "| **Speed** | âš ï¸ Slow to write | âœ… Very fast |\n",
    "| **Custom patterns** | âœ… Any pattern | âŒ Only ReAct |\n",
    "| **Debugging** | âœ… See everything | âš ï¸ Hidden internals |\n",
    "| **Production** | âœ… Both work equally well | âœ… Both work equally well |\n",
    "\n",
    "### Decision Guide\n",
    "\n",
    "**Use Manual Building When:**\n",
    "- âœ… Learning LangGraph\n",
    "- âœ… Need custom patterns (Plan-Execute, Self-RAG, CRAG)\n",
    "- âœ… Need fine control over graph structure\n",
    "- âœ… Building multi-agent systems\n",
    "- âœ… Debugging complex behavior\n",
    "\n",
    "**Use Helper Functions When:**\n",
    "- âœ… Simple ReAct pattern is enough\n",
    "- âœ… Rapid prototyping\n",
    "- âœ… You understand how it works internally\n",
    "- âœ… Standard tool-calling agent\n",
    "- âœ… Production code (if ReAct fits your needs)\n",
    "\n",
    "### Progression Strategy\n",
    "\n",
    "**Beginner:** Build manually to learn  \n",
    "â†“  \n",
    "**Intermediate:** Use helpers for simple cases, manual for complex  \n",
    "â†“  \n",
    "**Advanced:** Choose based on requirements, not convenience  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Plan-Execute Pattern\n",
    "\n",
    "### What is Plan-Execute?\n",
    "\n",
    "Instead of thinking step-by-step, the agent **plans everything upfront**:\n",
    "\n",
    "```\n",
    "User: \"Research Python and write a summary\"\n",
    "\n",
    "PLANNER:\n",
    "  Step 1: Search for Python information\n",
    "  Step 2: Read and understand content\n",
    "  Step 3: Write summary\n",
    "  Step 4: Review and polish\n",
    "\n",
    "EXECUTOR:\n",
    "  Execute Step 1 âœ“\n",
    "  Execute Step 2 âœ“\n",
    "  Execute Step 3 âœ“\n",
    "  Execute Step 4 âœ“\n",
    "\n",
    "DONE!\n",
    "```\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- Better for complex multi-step tasks\n",
    "- More predictable (plan visible upfront)\n",
    "- User sees progress\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- âœ… Complex tasks with clear steps\n",
    "- âœ… Long-running workflows\n",
    "- âœ… Need to show user the plan\n",
    "- âŒ Simple queries (overkill)\n",
    "- âŒ Highly dynamic tasks (hard to plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom state for Plan-Execute\n",
    "class PlanExecuteState(TypedDict):\n",
    "    \"\"\"State for plan-execute pattern.\"\"\"\n",
    "    input: str  # Original user query\n",
    "    plan: list[str]  # List of steps\n",
    "    current_step: int  # Which step we're on\n",
    "    results: Annotated[list[str], operator.add]  # Results from each step\n",
    "    final_output: str  # Final answer\n",
    "\n",
    "print(\"âœ… Plan-Execute state defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: Planner\n",
    "def planner(state: PlanExecuteState) -> dict:\n",
    "    \"\"\"Create a step-by-step plan.\"\"\"\n",
    "    prompt = f\"\"\"Create a step-by-step plan for this task:\n",
    "\n",
    "Task: {state['input']}\n",
    "\n",
    "Return a numbered list of concrete steps. Keep it simple (3-5 steps).\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Parse steps (simple parsing)\n",
    "    lines = response.content.split('\\n')\n",
    "    steps = [line.strip() for line in lines if line.strip() and any(char.isdigit() for char in line[:3])]\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ PLAN CREATED:\")\n",
    "    for step in steps:\n",
    "        print(f\"  {step}\")\n",
    "    print()\n",
    "    \n",
    "    return {\"plan\": steps, \"current_step\": 0, \"results\": []}\n",
    "\n",
    "# Node 2: Executor\n",
    "def executor(state: PlanExecuteState) -> dict:\n",
    "    \"\"\"Execute current step.\"\"\"\n",
    "    if state[\"current_step\"] >= len(state[\"plan\"]):\n",
    "        # All steps done\n",
    "        return {}\n",
    "    \n",
    "    current_step = state[\"plan\"][state[\"current_step\"]]\n",
    "    \n",
    "    print(f\"âš™ï¸ Executing: {current_step}\")\n",
    "    \n",
    "    # Execute step (simplified - just use LLM)\n",
    "    prompt = f\"\"\"Previous results: {state.get('results', [])}\\n\\nExecute this step: {current_step}\"\"\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    result = f\"Step {state['current_step'] + 1} result: {response.content}\"\n",
    "    print(result)\n",
    "    print(f\"âœ“ Done\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"results\": [result],\n",
    "        \"current_step\": state[\"current_step\"] + 1\n",
    "    }\n",
    "\n",
    "# Node 3: Finalizer\n",
    "def finalizer(state: PlanExecuteState) -> dict:\n",
    "    \"\"\"Create final output from all results.\"\"\"\n",
    "    prompt = f\"\"\"Combine these step results into a final answer:\n",
    "\n",
    "Original task: {state['input']}\n",
    "\n",
    "Results: {state['results']}\n",
    "\n",
    "Provide a clear, concise final answer.\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\"final_output\": response.content}\n",
    "\n",
    "print(\"âœ… Plan-Execute nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing function\n",
    "def should_continue_execution(state: PlanExecuteState) -> Literal[\"executor\", \"finalizer\"]:\n",
    "    \"\"\"Decide if more steps to execute.\"\"\"\n",
    "    if state[\"current_step\"] < len(state[\"plan\"]):\n",
    "        return \"executor\"\n",
    "    return \"finalizer\"\n",
    "\n",
    "# Build Plan-Execute graph\n",
    "plan_execute_builder = StateGraph(PlanExecuteState)\n",
    "\n",
    "plan_execute_builder.add_node(\"planner\", planner)\n",
    "plan_execute_builder.add_node(\"executor\", executor)\n",
    "plan_execute_builder.add_node(\"finalizer\", finalizer)\n",
    "\n",
    "plan_execute_builder.add_edge(START, \"planner\")\n",
    "plan_execute_builder.add_edge(\"planner\", \"executor\")\n",
    "plan_execute_builder.add_conditional_edges(\n",
    "    \"executor\",\n",
    "    should_continue_execution,\n",
    "    {\"executor\": \"executor\", \"finalizer\": \"finalizer\"}  # Can loop back to executor\n",
    ")\n",
    "plan_execute_builder.add_edge(\"finalizer\", END)\n",
    "\n",
    "plan_execute_agent = plan_execute_builder.compile()\n",
    "\n",
    "print(\"âœ… Plan-Execute agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "try:\n",
    "    display(Image(plan_execute_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph: START â†’ planner â†’ executor (loops) â†’ finalizer â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸŽ¨ Notice:** executor can loop back to itself until all steps done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Plan-Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plan_execute_agent.invoke({\n",
    "    \"input\": \"Research what ReAct pattern is and explain it simply\"\n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ðŸ“Š FINAL OUTPUT:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(result[\"final_output\"])\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plan_execute_agent.invoke({\n",
    "    \"input\": \"Research what ReAct pattern is and explain it simply\"\n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ðŸ“Š FINAL OUTPUT:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(result[\"final_output\"])\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸŽ¯ Observe:** You can see the plan and watch each step execute!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between ReAct and Execute\n",
    "| Aspect | ReAct | Plan-Execute |\n",
    "|--------|-------|--------------|\n",
    "| Decision-making | Agent decides at each step | Plan decided upfront |\n",
    "| Adaptability | High â€” can change strategy | Low â€” follows plan |\n",
    "| Workflow | Dynamic loop | Structured sequence |\n",
    "| Agent role | Active decision-maker | Executor of plan |\n",
    "| When to stop | Agent decides | When plan is done |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Reflection Pattern\n",
    "\n",
    "### What is Reflection?\n",
    "\n",
    "The agent **critiques its own work** and improves it:\n",
    "\n",
    "```\n",
    "1. GENERATE: Create initial answer\n",
    "2. REFLECT: Evaluate quality (what's wrong?)\n",
    "3. REFINE: Improve based on critique\n",
    "4. REPEAT: Until quality threshold met (or max iterations)\n",
    "```\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- Higher quality outputs\n",
    "- Self-correcting\n",
    "- Works for any generation task\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- âœ… Quality-critical tasks (writing, code)\n",
    "- âœ… Creative tasks that benefit from iteration\n",
    "- âœ… When you can define quality criteria\n",
    "- âŒ Simple Q&A (overkill)\n",
    "- âŒ Cost-sensitive (uses more tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom state for Reflection\n",
    "class ReflectionState(TypedDict):\n",
    "    \"\"\"State for reflection pattern.\"\"\"\n",
    "    task: str  # Original task\n",
    "    draft: str  # Current draft\n",
    "    critique: str  # Critique of draft\n",
    "    iterations: int  # Number of refinements\n",
    "    final_output: str  # Final result\n",
    "\n",
    "MAX_REFLECTIONS = 2  # Prevent infinite loops\n",
    "\n",
    "print(\"âœ… Reflection state defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: Generator\n",
    "def generator(state: ReflectionState) -> dict:\n",
    "    \"\"\"Generate or refine based on critique.\"\"\"\n",
    "    if state[\"iterations\"] == 0:\n",
    "        # First generation\n",
    "        prompt = f\"\"\"Create a response for this task:\n",
    "\n",
    "Task: {state['task']}\n",
    "\n",
    "Provide a clear, complete answer.\"\"\"\n",
    "        print(\"\\nâœï¸ Generating initial draft...\")\n",
    "    else:\n",
    "        # Refinement based on critique\n",
    "        prompt = f\"\"\"Improve this draft based on the critique:\n",
    "\n",
    "Task: {state['task']}\n",
    "\n",
    "Current draft: {state['draft']}\n",
    "\n",
    "Critique: {state['critique']}\n",
    "\n",
    "Create an improved version.\"\"\"\n",
    "        print(f\"\\nâœï¸ Refining (iteration {state['iterations']})...\")\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    print(\"âœ“ Draft created\\n\")\n",
    "    \n",
    "    return {\"draft\": response.content}\n",
    "\n",
    "# Node 2: Critic\n",
    "def critic(state: ReflectionState) -> dict:\n",
    "    \"\"\"Evaluate draft and provide critique.\"\"\"\n",
    "    prompt = f\"\"\"Evaluate this response and provide constructive critique:\n",
    "\n",
    "Task: {state['task']}\n",
    "\n",
    "Response: {state['draft']}\n",
    "\n",
    "Critique the response. What could be improved?\n",
    "If it's excellent, say \"APPROVED: explanation\".\n",
    "Otherwise, provide specific improvements needed.\"\"\"\n",
    "    \n",
    "    print(\"ðŸ” Critiquing draft...\")\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    critique = response.content\n",
    "    \n",
    "    print(f\"Critique: {critique[:100]}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"critique\": critique,\n",
    "        \"iterations\": state[\"iterations\"] + 1\n",
    "    }\n",
    "\n",
    "# Node 3: Finalizer\n",
    "def reflection_finalizer(state: ReflectionState) -> dict:\n",
    "    \"\"\"Set final output.\"\"\"\n",
    "    print(\"\\nâœ… Reflection complete!\\n\")\n",
    "    return {\"final_output\": state[\"draft\"]}\n",
    "\n",
    "print(\"âœ… Reflection nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing function\n",
    "def should_reflect_again(state: ReflectionState) -> Literal[\"generator\", \"finalizer\"]:\n",
    "    \"\"\"Decide if we need more refinement.\"\"\"\n",
    "    # Stop if approved or max iterations\n",
    "    if \"APPROVED\" in state.get(\"critique\", \"\").upper():\n",
    "        return \"finalizer\"\n",
    "    \n",
    "    if state[\"iterations\"] >= MAX_REFLECTIONS:\n",
    "        print(f\"âš ï¸ Max iterations ({MAX_REFLECTIONS}) reached\\n\")\n",
    "        return \"finalizer\"\n",
    "    \n",
    "    return \"generator\"\n",
    "\n",
    "# Build Reflection graph\n",
    "reflection_builder = StateGraph(ReflectionState)\n",
    "\n",
    "reflection_builder.add_node(\"generator\", generator)\n",
    "reflection_builder.add_node(\"critic\", critic)\n",
    "reflection_builder.add_node(\"finalizer\", reflection_finalizer)\n",
    "\n",
    "reflection_builder.add_edge(START, \"generator\")\n",
    "reflection_builder.add_edge(\"generator\", \"critic\")\n",
    "reflection_builder.add_conditional_edges(\n",
    "    \"critic\",\n",
    "    should_reflect_again,\n",
    "    {\"generator\": \"generator\", \"finalizer\": \"finalizer\"}  # Can loop back\n",
    ")\n",
    "reflection_builder.add_edge(\"finalizer\", END)\n",
    "\n",
    "reflection_agent = reflection_builder.compile()\n",
    "\n",
    "print(\"âœ… Reflection agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "try:\n",
    "    display(Image(reflection_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph: START â†’ generator â†’ critic (loops back to generator) â†’ finalizer â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸŽ¨ Notice:** critic can send back to generator for refinement!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reflection_agent.invoke({\n",
    "    \"task\": \"Explain what an agentic pattern is in 2-3 sentences\",\n",
    "    \"draft\": \"\",\n",
    "    \"critique\": \"\",\n",
    "    \"iterations\": 0\n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ðŸ“Š FINAL OUTPUT (after reflection):\")\n",
    "print(f\"{'='*70}\")\n",
    "print(result[\"final_output\"])\n",
    "print(f\"\\nTotal iterations: {result['iterations']}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸŽ¯ Observe:** You can see the agent refining its own work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 9: Pattern Comparison\n",
    "\n",
    "| Pattern | Best For | Pros | Cons | Helper Available? |\n",
    "|---------|----------|------|------|------------------|\n",
    "| **ReAct** | General tool usage | Simple, flexible | Can be inefficient | âœ… Yes |\n",
    "| **Plan-Execute** | Complex multi-step tasks | Predictable, transparent | Less adaptive | âŒ No |\n",
    "| **Reflection** | Quality-critical outputs | Self-improving | Higher cost | âŒ No |\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "**ReAct:**\n",
    "- âœ… Chatbots with tools\n",
    "- âœ… RAG systems (retrieve as needed)\n",
    "- âœ… General Q&A with actions\n",
    "\n",
    "**Plan-Execute:**\n",
    "- âœ… Research tasks\n",
    "- âœ… Multi-step workflows\n",
    "- âœ… Tasks needing transparency\n",
    "\n",
    "**Reflection:**\n",
    "- âœ… Content writing\n",
    "- âœ… Code generation\n",
    "- âœ… Creative tasks\n",
    "- âœ… Quality > speed scenarios\n",
    "\n",
    "### Can You Combine Them?\n",
    "\n",
    "Yes! Common combinations:\n",
    "- **Plan-Execute + ReAct:** Each step uses ReAct for tools\n",
    "- **Reflection + ReAct:** Reflect on tool usage decisions\n",
    "- **Plan-Execute + Reflection:** Reflect on entire plan\n",
    "\n",
    "Advanced agents often use multiple patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 10: Summary\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **ReAct Pattern**\n",
    "   - Reason â†’ Act â†’ Observe cycle\n",
    "   - Built manually and with helper\n",
    "   - Most common agent pattern\n",
    "\n",
    "2. **Plan-Execute Pattern**\n",
    "   - Plan upfront, execute sequentially\n",
    "   - Better for complex tasks\n",
    "   - More predictable than ReAct\n",
    "\n",
    "3. **Reflection Pattern**\n",
    "   - Generate â†’ Critique â†’ Refine\n",
    "   - Self-improving agents\n",
    "   - Higher quality outputs\n",
    "\n",
    "4. **Manual vs Helpers**\n",
    "   - Helpers great for simple ReAct\n",
    "   - Manual needed for custom patterns\n",
    "   - Choose based on requirements\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **No one-size-fits-all** - Choose pattern for your use case\n",
    "- **Start simple** - ReAct is often enough\n",
    "- **Iterate** - Begin with basic, add complexity as needed\n",
    "- **Understand internals** - Build manually first, use helpers later\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Notebook 5: Multi-Agent Systems**\n",
    "- Multiple agents working together\n",
    "- Supervisor, collaborative, and debate patterns\n",
    "- Scaling from single to multi-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ Practice Exercises\n",
    "\n",
    "### Exercise 1: Adaptive Reflection with Quality Metrics\n",
    "\n",
    "**Task:** Improve Reflection with numerical quality scoring.\n",
    "\n",
    "**Requirements:**\n",
    "1. Critic scores draft on multiple criteria (1-5 each):\n",
    "   - Clarity\n",
    "   - Completeness\n",
    "   - Accuracy\n",
    "2. Use Pydantic model for structured scoring\n",
    "3. Only refine if any score < 4\n",
    "4. Track score improvements across iterations\n",
    "5. Stop when all scores â‰¥ 4 or max iterations\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Iteration 1: Clarity=3, Completeness=4, Accuracy=5 â†’ Refine\n",
    "Iteration 2: Clarity=5, Completeness=4, Accuracy=5 â†’ Approved!\n",
    "```\n",
    "\n",
    "**Deliverables:**\n",
    "- Reflection agent with quality metrics\n",
    "- Test with task requiring refinement\n",
    "- Visualize score improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Plan-Execute + Reflection Hybrid\n",
    "\n",
    "**Task:** Combine Plan-Execute and Reflection patterns to create a high-quality multi-step agent.\n",
    "\n",
    "**Concept:** Use Plan-Execute to break down complex tasks, then use Reflection on the final output to ensure quality.\n",
    "\n",
    "**Requirements:**\n",
    "1. Create a hybrid state that includes:\n",
    "   - Plan-Execute state (input, plan, current_step, results)\n",
    "   - Reflection state (draft, critique, iterations)\n",
    "2. Flow: Planner â†’ Executor (loop) â†’ Generator (uses results) â†’ Critic â†’ Refiner (if needed) â†’ Finalizer\n",
    "3. The Generator creates initial output from all executor results\n",
    "4. The Critic evaluates the complete output (not individual steps)\n",
    "5. Refine the final output based on critique (max 2 reflection iterations)\n",
    "6. Track both execution progress AND reflection quality\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "START\n",
    "  â†“\n",
    "Planner (creates plan)\n",
    "  â†“\n",
    "Executor (executes each step)\n",
    "  â†“ (loops until all steps done)\n",
    "  â†“\n",
    "Generator (synthesizes results into draft)\n",
    "  â†“\n",
    "Critic (evaluates quality)\n",
    "  â†“\n",
    "Should Refine?\n",
    "  â†“              â†“\n",
    "Refiner       Finalizer\n",
    "  â†“              â†“\n",
    "Critic         END\n",
    "  (loops)\n",
    "```\n",
    "\n",
    "**Test scenario:**\n",
    "```\n",
    "Task: \"Research the benefits of Python programming, create a summary, and make it beginner-friendly\"\n",
    "\n",
    "Expected flow:\n",
    "1. PLAN: \n",
    "   - Step 1: Search for Python benefits\n",
    "   - Step 2: Identify key benefits\n",
    "   - Step 3: Create summary\n",
    "2. EXECUTE: Complete all steps\n",
    "3. GENERATE: Create initial summary from results\n",
    "4. REFLECT: Critique summary for beginner-friendliness\n",
    "5. REFINE: Simplify language and add examples\n",
    "6. FINAL: High-quality, beginner-friendly summary\n",
    "```\n",
    "\n",
    "**Deliverables:**\n",
    "1. Combined state definition (TypedDict)\n",
    "2. All necessary nodes (planner, executor, generator, critic, refiner, finalizer)\n",
    "3. Graph with proper edges and conditional routing\n",
    "4. Test with the scenario above\n",
    "5. Print output showing:\n",
    "   - The plan\n",
    "   - Each execution step\n",
    "   - Initial draft\n",
    "   - Critique\n",
    "   - Refined version (if applicable)\n",
    "   - Final output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "1. **Why is ReAct the most popular agent pattern?**\n",
    "\n",
    "2. **When would Plan-Execute fail but ReAct succeed?**\n",
    "\n",
    "3. **How does Reflection pattern differ from Self-RAG?**\n",
    "\n",
    "4. **Why don't helpers exist for Plan-Execute or Reflection?**\n",
    "\n",
    "5. **Could you build a \"Plan-Execute-Reflect\" hybrid? How?**\n",
    "\n",
    "6. **What are the cost implications of each pattern?**\n",
    "\n",
    "Think about these patterns as you build agents!\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ‰ Notebook 4 Complete!**\n",
    "\n",
    "You now understand core agentic patterns. Next: Multi-Agent Systems! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bao_env (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
