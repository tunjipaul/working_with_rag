{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technique 3: Semantic Chunking\n",
    "\n",
    "## The Problem\n",
    "Fixed-size chunking (every 500 tokens) **breaks semantic boundaries**:\n",
    "- Splits mid-sentence\n",
    "- Splits mid-paragraph\n",
    "- Splits mid-topic\n",
    "\n",
    "Result: Chunks lack coherent meaning!\n",
    "\n",
    "## The Solution\n",
    "**Semantic Chunking:** Split based on meaning, not size.\n",
    "\n",
    "Uses embeddings to detect topic shifts and split there.\n",
    "\n",
    "**Difficulty:** ⭐⭐⭐☆☆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_openai import setup_openai_api, create_embeddings, create_llm, load_msme_data\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "print('[OK] Imports done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = setup_openai_api()\n",
    "embeddings = create_embeddings(api_key)\n",
    "llm = create_llm(api_key)\n",
    "docs, metas, ids = load_msme_data('msme.csv')\n",
    "print('[OK] Data loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Semantic Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_chunker = SemanticChunker(embeddings)\n",
    "print('[OK] Semantic chunker ready!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split Documents\n",
    "Combine all docs and split semantically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = '\\n\\n'.join(docs)\n",
    "semantic_chunks = semantic_chunker.create_documents([combined_text])\n",
    "\n",
    "print(f'Original docs: {len(docs)}')\n",
    "print(f'Semantic chunks: {len(semantic_chunks)}')\n",
    "print(f'\\nSample chunk lengths:')\n",
    "for i in range(min(5, len(semantic_chunks))):\n",
    "    print(f'  Chunk {i+1}: {len(semantic_chunks[i].page_content)} chars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compare with Fixed Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "fixed_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\n",
    "fixed_chunks = fixed_splitter.create_documents([combined_text])\n",
    "\n",
    "print(f'Fixed chunks (500 chars): {len(fixed_chunks)}')\n",
    "print(f'Semantic chunks: {len(semantic_chunks)}')\n",
    "print(f'\\nFixed chunk example (may break mid-sentence):')\n",
    "print(fixed_chunks[0].page_content[:300])\n",
    "print(f'\\nSemantic chunk example (respects boundaries):')\n",
    "print(semantic_chunks[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fixed_chunks[0].page_content)\n",
    "print(semantic_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚖️ Fixed vs Semantic Chunking Trade-offs\n",
    "\n",
    "| Aspect | Fixed-Size Chunking | Semantic Chunking |\n",
    "|--------|-------------------|-------------------|\n",
    "| **Chunk Count** | More chunks (812) | Fewer chunks (83) |\n",
    "| **Chunk Sizes** | Uniform (~500 chars) | Variable (79-11,065 chars) |\n",
    "| **Semantic Coherence** | Often broken ❌ | Always preserved ✅ |\n",
    "| **Processing Speed** | Fast | Slower (embedding overhead) |\n",
    "| **Setup Complexity** | Simple | Requires embedding model |\n",
    "| **Context Quality** | May include incomplete ideas | Complete thoughts only |\n",
    "| **Best For** | Speed, simplicity | Quality, coherence |\n",
    "\n",
    "### Real Impact on Retrieval\n",
    "\n",
    "**Scenario:** Query about \"business registration requirements\"\n",
    "\n",
    "**Fixed Chunking:**\n",
    "```\n",
    "Retrieved Chunk: \"...visit the CAC portal. Submit required documen\"\n",
    "                                                              ↑ CUT OFF!\n",
    "Problem: User gets incomplete information\n",
    "```\n",
    "\n",
    "**Semantic Chunking:**\n",
    "```\n",
    "Retrieved Chunk: \"To register a business, visit the CAC portal. \n",
    "                  Submit required documents including tax ID, \n",
    "                  proof of address, and business plan. The process \n",
    "                  takes 2-3 weeks...\"\n",
    "                                                              ↑ COMPLETE!\n",
    "Result: User gets full, actionable answer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the Extra Cost is Worth It\n",
    "\n",
    "✅ **Use Semantic Chunking When:**\n",
    "- Documents contain flowing narratives (articles, guides, reports)\n",
    "- Context matters (legal, medical, educational content)\n",
    "- Users ask conceptual questions requiring complete explanations\n",
    "- Quality > speed\n",
    "\n",
    "❌ **Stick with Fixed Chunking When:**\n",
    "- Documents are already well-structured (bullet points, tables)\n",
    "- Speed is critical (real-time applications)\n",
    "- Documents are short and uniform\n",
    "- Simple lookups (definitions, FAQs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Compare retrieval quality with semantic vs fixed chunks\n",
    "2. Test with different document types\n",
    "3. Measure impact on answer coherence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next:** Technique 4 - Reranking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bao_env (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
