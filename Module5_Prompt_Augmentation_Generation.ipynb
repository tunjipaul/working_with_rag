{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Prompt Augmentation & Generation\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Structure effective RAG prompts\n",
    "- Inject retrieved context optimally\n",
    "- Implement citation systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the libraries we'll need and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "from typing import List, Dict\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Understanding RAG Prompt Structure\n",
    "\n",
    "In a basic RAG system, we need to:\n",
    "1. **Retrieve** relevant chunks (covered in Module 4)\n",
    "2. **Augment** the prompt with retrieved context (this module)\n",
    "3. **Generate** a response using the LLM\n",
    "\n",
    "### Components of a RAG Prompt\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  SYSTEM MESSAGE                     â”‚\n",
    "â”‚  - Define role and constraints      â”‚\n",
    "â”‚  - Instruct to use only context     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  CONTEXT (Retrieved Chunks)         â”‚\n",
    "â”‚  [Chunk 1] Source: doc1.pdf         â”‚\n",
    "â”‚  Content: ...                       â”‚\n",
    "â”‚                                     â”‚\n",
    "â”‚  [Chunk 2] Source: doc2.pdf         â”‚\n",
    "â”‚  Content: ...                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  USER QUERY                         â”‚\n",
    "â”‚  Question: {user_question}          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  INSTRUCTIONS                       â”‚\n",
    "â”‚  - How to cite sources              â”‚\n",
    "â”‚  - What to do if uncertain          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic RAG Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic RAG prompt template\n",
    "BASIC_RAG_TEMPLATE = \"\"\"\n",
    "You are a helpful assistant that answers questions based on provided context.\n",
    "Use ONLY the information from the context below to answer the question.\n",
    "If the answer cannot be found in the context, say \"I don't have enough information to answer this question.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Example usage\n",
    "sample_context = \"\"\"\n",
    "[1] RAG stands for Retrieval-Augmented Generation. It's a technique that combines information retrieval with text generation.\n",
    "[2] The main benefit of RAG is that it allows LLMs to access external knowledge without retraining.\n",
    "\"\"\"\n",
    "\n",
    "sample_question = \"What does RAG stand for?\"\n",
    "\n",
    "prompt = BASIC_RAG_TEMPLATE.format(\n",
    "    context=sample_context,\n",
    "    question=sample_question\n",
    ")\n",
    "\n",
    "print(\"Generated Prompt:\")\n",
    "print(\"=\"*50)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤” Reflection\n",
    "\n",
    "Why do we need explicit instructions like \"use ONLY the information from the context\"?\n",
    "\n",
    "<details>\n",
    "<summary>Click to see answer</summary>\n",
    "Without explicit constraints, LLMs will use their pre-trained knowledge to answer questions, which defeats the purpose of RAG. We want answers grounded in our specific documents, not general knowledge that might be outdated or incorrect for our use case.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Context Injection Strategies\n",
    "\n",
    "How we format and present retrieved chunks significantly impacts answer quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1: Simple Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate retrieved chunks (normally from Module 4's retrieval system)\n",
    "retrieved_chunks = [\n",
    "    {\n",
    "        \"content\": \"Python is a high-level programming language known for its simple syntax and readability.\",\n",
    "        \"source\": \"python_basics.pdf\",\n",
    "        \"score\": 0.89\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"Python supports multiple programming paradigms including procedural, object-oriented, and functional programming.\",\n",
    "        \"source\": \"python_guide.pdf\",\n",
    "        \"score\": 0.85\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"Python was created by Guido van Rossum and first released in 1991.\",\n",
    "        \"source\": \"python_history.pdf\",\n",
    "        \"score\": 0.72\n",
    "    }\n",
    "]\n",
    "\n",
    "# Simple concatenation\n",
    "def format_context_simple(chunks: List[Dict]) -> str:\n",
    "    \"\"\"Simply concatenate all chunk content.\"\"\"\n",
    "    return \"\\n\\n\".join([chunk[\"content\"] for chunk in chunks])\n",
    "\n",
    "context_simple = format_context_simple(retrieved_chunks)\n",
    "print(\"Simple Concatenation:\")\n",
    "print(\"=\"*50)\n",
    "print(context_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2: Numbered Context (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context_numbered(chunks: List[Dict]) -> str:\n",
    "    \"\"\"Format chunks with numbers for citation.\"\"\"\n",
    "    formatted = []\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        formatted.append(f\"[{i}] {chunk['content']}\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "context_numbered = format_context_numbered(retrieved_chunks)\n",
    "print(\"Numbered Context:\")\n",
    "print(\"=\"*50)\n",
    "print(context_numbered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 3: Context with Metadata (Best for Production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context_with_metadata(chunks: List[Dict]) -> str:\n",
    "    \"\"\"Format chunks with source metadata for better attribution.\"\"\"\n",
    "    formatted = []\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        formatted.append(\n",
    "            f\"[{i}] (Source: {chunk['source']}, Relevance: {chunk['score']:.2f})\\n\"\n",
    "            f\"{chunk['content']}\"\n",
    "        )\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "context_with_metadata = format_context_with_metadata(retrieved_chunks)\n",
    "print(\"Context with Metadata:\")\n",
    "print(\"=\"*50)\n",
    "print(context_with_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Which is Better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Strategy Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. Simple Concatenation\")\n",
    "print(\"   âœ… Pros: Clean, minimal tokens\")\n",
    "print(\"   âŒ Cons: No citations possible, hard to track sources\")\n",
    "print(\"\\n2. Numbered Context\")\n",
    "print(\"   âœ… Pros: Enables citations, clear separation\")\n",
    "print(\"   âŒ Cons: Slightly more tokens\")\n",
    "print(\"   ğŸ‘ Recommended: Good balance\")\n",
    "print(\"\\n3. Context with Metadata\")\n",
    "print(\"   âœ… Pros: Full traceability, source attribution\")\n",
    "print(\"   âŒ Cons: Most tokens, may confuse some LLMs\")\n",
    "print(\"   ğŸ‘ Best for: Production systems requiring full audit trail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Prompt Templates for Different Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template 1: Basic Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_TEMPLATE = \"\"\"\n",
    "You are a helpful AI assistant. Answer the user's question based on the context provided below.\n",
    "\n",
    "Important guidelines:\n",
    "- Use ONLY information from the context\n",
    "- If the answer is not in the context, say \"I don't have enough information to answer this question.\"\n",
    "- Be concise and accurate\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(QA_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template 2: Q&A with Citations (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_WITH_CITATIONS_TEMPLATE = \"\"\"\n",
    "You are a helpful AI assistant. Answer the user's question based on the context provided below.\n",
    "\n",
    "Important guidelines:\n",
    "- Use ONLY information from the context\n",
    "- Cite your sources using [1], [2], etc.\n",
    "- If multiple sources support a claim, cite all: [1][2]\n",
    "- If the answer is not in the context, say \"I don't have enough information to answer this question.\"\n",
    "- Be concise and accurate\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer (remember to cite sources):\n",
    "\"\"\"\n",
    "\n",
    "print(QA_WITH_CITATIONS_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template 3: Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARIZATION_TEMPLATE = \"\"\"\n",
    "You are a helpful AI assistant. Create a concise summary of the following information.\n",
    "\n",
    "Guidelines:\n",
    "- Include only the most important points\n",
    "- Keep the summary under 150 words\n",
    "- Use bullet points if appropriate\n",
    "- Maintain factual accuracy\n",
    "\n",
    "Content to summarize:\n",
    "{context}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "print(SUMMARIZATION_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template 4: Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPARISON_TEMPLATE = \"\"\"\n",
    "You are a helpful AI assistant. Compare and contrast the information provided in the context.\n",
    "\n",
    "Guidelines:\n",
    "- Identify similarities and differences\n",
    "- Organize your comparison clearly\n",
    "- Cite sources using [1], [2], etc.\n",
    "- If information conflicts, present both sides\n",
    "- Use ONLY information from the context\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Comparative Analysis:\n",
    "\"\"\"\n",
    "\n",
    "print(COMPARISON_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **RAG Prompt Structure**\n",
    "   - System message, context, query, instructions\n",
    "   - Importance of explicit constraints\n",
    "\n",
    "2. **Context Injection Strategies**\n",
    "   - Simple concatenation vs numbered vs metadata\n",
    "   - Best practices for formatting multiple chunks\n",
    "\n",
    "3. **Prompt Templates**\n",
    "   - Q&A, summarization, comparison templates\n",
    "   - Citation-enforcing templates\n",
    "\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "âœ… Always be explicit about using only provided context\n",
    "\n",
    "âœ… Number chunks to enable citations\n",
    "\n",
    "âœ… Use low temperature (0.0-0.3) for factual RAG\n",
    "\n",
    "âœ… Test with diverse queries\n",
    "\n",
    "âœ… Keep implementations simple and focused\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **Module 6**, we'll:\n",
    "- Integrate everything from Modules 1-5\n",
    "- Build a complete end-to-end RAG system\n",
    "\n",
    "**You're now ready to generate responses from retrieved context!** ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "publica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
