{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Technique 0: Setup & Baseline RAG\n",
        "\n",
        "## üéØ Welcome to Advanced RAG Techniques!\n",
        "\n",
        "This notebook establishes the **foundation** for all advanced techniques you'll learn.\n",
        "\n",
        "### What You'll Do:\n",
        "1. Set up your environment\n",
        "2. Load the MSME dataset\n",
        "3. Build a basic RAG system\n",
        "4. Establish baseline metrics\n",
        "5. Test with sample queries\n",
        "\n",
        "### Why This Matters:\n",
        "Every advanced technique will be compared against this baseline. Understanding where we start helps you appreciate the improvements!\n",
        "\n",
        "**Difficulty:** ‚≠ê‚òÜ‚òÜ‚òÜ‚òÜ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Prerequisites\n",
        "\n",
        "Before starting, ensure you have:\n",
        "- ‚úÖ Python 3.8+\n",
        "- ‚úÖ Together AI API key\n",
        "- ‚úÖ Installed dependencies (see requirements.txt)\n",
        "- ‚úÖ `msme.csv` in this directory\n",
        "- ‚úÖ `.env` file with your API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries\n",
        "\n",
        "We'll use our custom `utils.py` module along with LangChain components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import utilities\n",
        "from utils_openai import (\n",
        "    setup_openai_api,\n",
        "    load_msme_data,\n",
        "    create_embeddings,\n",
        "    create_llm,\n",
        "    create_vectorstore,\n",
        "    get_baseline_prompt,\n",
        "    print_retrieval_results,\n",
        "    count_tokens_approximate\n",
        ")\n",
        "\n",
        "# LangChain components\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Setup Together AI API\n",
        "\n",
        "Load your API key from the `.env` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load API key\n",
        "api_key = setup_openai_api()\n",
        "print(\"‚úÖ API key loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load MSME Dataset\n",
        "\n",
        "Our knowledge base contains 14 documents about MSMEs in Nigeria:\n",
        "- Business registration procedures\n",
        "- Financing options and policies\n",
        "- Government support programs\n",
        "- Industry-specific guidance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the MSME data\n",
        "documents, metadatas, ids = load_msme_data(\"msme.csv\")\n",
        "\n",
        "print(f\"\\nDataset Overview:\")\n",
        "print(f\"- Total documents: {len(documents)}\")\n",
        "print(f\"- Sample title: {metadatas[0]['doc_title']}\")\n",
        "print(f\"- Average doc length: {sum(len(d) for d in documents) // len(documents)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize Models\n",
        "\n",
        "We'll use:\n",
        "- **Embeddings:** M2-BERT-80M-32K (32,768 token context)\n",
        "- **LLM:** Llama 3.3 70B Turbo (fast and accurate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create embeddings model\n",
        "embeddings = create_embeddings(api_key)\n",
        "\n",
        "# Create chat model\n",
        "llm = create_llm(api_key, temperature=0)\n",
        "\n",
        "print(\"\\n‚úÖ Models initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Vector Store\n",
        "\n",
        "We'll use ChromaDB to store document embeddings for fast similarity search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create vector store\n",
        "vectorstore = create_vectorstore(\n",
        "    documents=documents,\n",
        "    metadatas=metadatas,\n",
        "    ids=ids,\n",
        "    embeddings=embeddings,\n",
        "    collection_name=\"msme_baseline\",\n",
        "    persist_directory=\"./chroma_db_baseline\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Vector store created and persisted!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create Retriever\n",
        "\n",
        "The retriever will find the most relevant documents for a given query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create retriever (retrieve top 5 documents)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "# Test retrieval\n",
        "test_query = \"Procedure and legal requirements for setting up a business in Nigeria\"\n",
        "retrieved_docs = retriever.invoke(test_query)\n",
        "\n",
        "print(f\"Retrieved {len(retrieved_docs)} documents for query:\")\n",
        "print(f\"'{test_query}'\")\n",
        "print_retrieval_results(retrieved_docs, max_docs=2, max_chars=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_retrieval_results(retrieved_docs, max_docs=5, max_chars=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Build Baseline RAG Chain\n",
        "\n",
        "Using **modern LCEL** (LangChain Expression Language) pattern - NOT deprecated RetrievalQA!\n",
        "\n",
        "### The Pipeline:\n",
        "1. Query comes in\n",
        "2. Retriever finds relevant docs\n",
        "3. Prompt combines docs + query\n",
        "4. LLM generates answer\n",
        "5. Output parser extracts text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get prompt template\n",
        "prompt = get_baseline_prompt()\n",
        "\n",
        "# Build the RAG chain (Modern LCEL pattern)\n",
        "baseline_rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Baseline RAG chain created!\")\n",
        "print(\"\\nChain structure:\")\n",
        "print(\"  Query ‚Üí Retriever ‚Üí Prompt ‚Üí LLM ‚Üí Answer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Test with Sample Queries\n",
        "\n",
        "Let's test our baseline RAG system with various queries about MSMEs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Query 1\n",
        "question1 = \"Explain the procedure and legal requirements for setting up a business in Nigeria\"\n",
        "\n",
        "print(f\"Question: {question1}\\n\")\n",
        "answer1 = baseline_rag_chain.invoke(question1)\n",
        "print(f\"Answer: {answer1}\")\n",
        "print(f\"\\n{'='*80}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Query 2\n",
        "question2 = \"What are the financing options for small businesses in Nigeria?\"\n",
        "\n",
        "print(f\"Question: {question2}\\n\")\n",
        "answer2 = baseline_rag_chain.invoke(question2)\n",
        "print(f\"Answer: {answer2}\")\n",
        "print(f\"\\n{'='*80}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Query 3\n",
        "question3 = \"What is the Development Bank of Nigeria loan repayment plan?\"\n",
        "\n",
        "print(f\"Question: {question3}\\n\")\n",
        "answer3 = baseline_rag_chain.invoke(question3)\n",
        "print(f\"Answer: {answer3}\")\n",
        "print(f\"\\n{'='*80}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Establish Baseline Metrics\n",
        "\n",
        "These metrics will be our comparison point for all advanced techniques.\n",
        "\n",
        "We'll measure:\n",
        "- Number of documents retrieved\n",
        "- Total tokens in context\n",
        "- Approximate cost\n",
        "- Answer quality (subjective)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate baseline metrics for question 1\n",
        "retrieved_for_q1 = retriever.invoke(question1)\n",
        "total_context = \"\\n\\n\".join([doc.page_content for doc in retrieved_for_q1])\n",
        "token_count = count_tokens_approximate(total_context)\n",
        "\n",
        "print(\"üìä BASELINE METRICS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Query: '{question1}'\")\n",
        "print(f\"\\nRetrieval:\")\n",
        "print(f\"  - Documents retrieved: {len(retrieved_for_q1)}\")\n",
        "print(f\"  - Total context tokens: ~{token_count}\")\n",
        "print(f\"  - Average tokens per doc: ~{token_count // len(retrieved_for_q1)}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Summary\n",
        "\n",
        "**What you built:**\n",
        "- ‚úÖ Loaded MSME dataset (14 documents)\n",
        "- ‚úÖ Created embeddings with M2-BERT\n",
        "- ‚úÖ Built vector store with ChromaDB\n",
        "- ‚úÖ Implemented modern RAG chain with LCEL\n",
        "- ‚úÖ Established baseline metrics\n",
        "\n",
        "**Current System:**\n",
        "- Retrieves top 5 documents based on semantic similarity\n",
        "- Uses ~3500-6000 tokens of context per query\n",
        "- Works well for straightforward questions\n",
        "\n",
        "**Limitations (what we'll improve):**\n",
        "- ‚ùå Misses exact keyword matches\n",
        "- ‚ùå Can't handle vague queries well\n",
        "- ‚ùå Retrieves too much irrelevant context\n",
        "- ‚ùå Fixed chunk size may break meaning\n",
        "- ‚ùå No way to rerank or refine results\n",
        "\n",
        "**Next:** Technique 1 - BM25 Hybrid Search will address keyword matching!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí™ Exercise: Explore the Baseline\n",
        "\n",
        "**Task:**\n",
        "1. Try 3 more queries of your own about Nigerian MSMEs\n",
        "2. For each query:\n",
        "   - Note how many retrieved docs seem relevant\n",
        "   - Rate the answer quality (1-10)\n",
        "   - Calculate approximate token usage\n",
        "3. Identify one query where the system struggles\n",
        "\n",
        "**Example queries to try:**\n",
        "- \"What are the tax benefits for small businesses?\"\n",
        "- \"How long does business registration take?\"\n",
        "- \"What is SMEDAN and what do they do?\"\n",
        "- \"Can I get a loan for my tech startup?\"\n",
        "\n",
        "**Expected Outcome:**\n",
        "You should find at least one query where:\n",
        "- The system retrieves irrelevant documents, OR\n",
        "- Misses documents with exact keyword matches, OR\n",
        "- The answer is incomplete/vague\n",
        "\n",
        "**Time:** 10 minutes\n",
        "\n",
        "**Document your findings in the cell below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your Exercise Code Here\n",
        "\n",
        "# Query 1:\n",
        "my_query_1 = \"\"  # Add your query\n",
        "# answer_1 = baseline_rag_chain.invoke(my_query_1)\n",
        "\n",
        "# Query 2:\n",
        "my_query_2 = \"\"  # Add your query\n",
        "# answer_2 = baseline_rag_chain.invoke(my_query_2)\n",
        "\n",
        "# Query 3:\n",
        "my_query_3 = \"\"  # Add your query\n",
        "# answer_3 = baseline_rag_chain.invoke(my_query_3)\n",
        "\n",
        "# Document your findings:\n",
        "print(\"My Findings:\")\n",
        "print(\"- Struggling query: [describe which query struggled]\")\n",
        "print(\"- Why it struggled: [explain the issue]\")\n",
        "print(\"- Potential solution: [which technique might help?]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Next Steps:**\n",
        "- ‚û°Ô∏è **Technique 1:** Contextual Compression Retrieval"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bao_env (3.10.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
